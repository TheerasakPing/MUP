{"version":3,"file":"providerOptions.js","sourceRoot":"","sources":["../../../../src/common/utils/ai/providerOptions.ts"],"names":[],"mappings":";AAAA;;;;GAIG;;;AAQH,sDAMiC;AACjC,6CAA0C;AAE1C,qCAAiD;AAyBjD;;;;;;;;;;;;;;;;;GAiBG;AACH,8BACE,WAAmB,EACnB,aAA4B,EAC5B,QAAuB,EACvB,eAAyC,EACzC,kBAAuC,EACvC,WAAoB,EAAE,oCAAoC;AAC1D,oBAAmE,EAClD;IACjB,oFAAoF;IACpF,sDAAsD;IACtD,MAAM,iBAAiB,GAAG,aAAa,CAAC;IACxC,8CAA8C;IAC9C,MAAM,CAAC,QAAQ,EAAE,SAAS,CAAC,GAAG,IAAA,8BAAqB,EAAC,WAAW,CAAC,CAAC,KAAK,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC;IAE/E,SAAG,CAAC,KAAK,CAAC,sBAAsB,EAAE;QAChC,WAAW;QACX,QAAQ;QACR,SAAS;QACT,aAAa;KACd,CAAC,CAAC;IAEH,IAAI,CAAC,QAAQ,IAAI,CAAC,SAAS,EAAE,CAAC;QAC5B,SAAG,CAAC,KAAK,CAAC,wEAAwE,CAAC,CAAC;QACpF,OAAO,EAAE,CAAC;IACZ,CAAC;IAED,mCAAmC;IACnC,IAAI,QAAQ,KAAK,WAAW,EAAE,CAAC;QAC7B,4DAA4D;QAC5D,0EAA0E;QAC1E,8DAA8D;QAC9D,MAAM,QAAQ,GAAG,SAAS,EAAE,QAAQ,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC;QAC1D,MAAM,QAAQ,GAAG,SAAS,EAAE,QAAQ,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC;QAE1D,IAAI,QAAQ,IAAI,QAAQ,EAAE,CAAC;YACzB,mEAAmE;YACnE,MAAM,WAAW,GAAG,IAAA,6BAAkB,EAAC,iBAAiB,CAAC,CAAC;YAC1D,MAAM,YAAY,GAAG,qCAA0B,CAAC,iBAAiB,CAAC,CAAC;YACnE,yDAAyD;YACzD,6EAA6E;YAC7E,MAAM,QAAQ,GAAyC,QAAQ;gBAC7D,CAAC,CAAC,iBAAiB,KAAK,KAAK;oBAC3B,CAAC,CAAC,EAAE,IAAI,EAAE,UAAU,EAAE;oBACtB,CAAC,CAAC,EAAE,IAAI,EAAE,UAAU,EAAE;gBACxB,CAAC,CAAC,YAAY,GAAG,CAAC;oBAChB,CAAC,CAAC,EAAE,IAAI,EAAE,SAAS,EAAE,YAAY,EAAE;oBACnC,CAAC,CAAC,SAAS,CAAC;YAEhB,SAAG,CAAC,KAAK,CAAC,qDAAqD,EAAE;gBAC/D,MAAM,EAAE,WAAW;gBACnB,QAAQ;gBACR,aAAa,EAAE,iBAAiB;aACjC,CAAC,CAAC;YAEH,OAAO;gBACL,SAAS,EAAE;oBACT,sBAAsB,EAAE,KAAK;oBAC7B,aAAa,EAAE,IAAI;oBACnB,GAAG,CAAC,QAAQ,IAAI,EAAE,QAAQ,EAAE,CAAC;oBAC7B,MAAM,EAAE,WAAW;iBACpB;aACF,CAAC;QACJ,CAAC;QAED,mEAAmE;QACnE,MAAM,YAAY,GAAG,qCAA0B,CAAC,iBAAiB,CAAC,CAAC;QACnE,SAAG,CAAC,KAAK,CAAC,wCAAwC,EAAE;YAClD,YAAY;YACZ,aAAa,EAAE,iBAAiB;SACjC,CAAC,CAAC;QAEH,MAAM,OAAO,GAAoB;YAC/B,SAAS,EAAE;gBACT,sBAAsB,EAAE,KAAK,EAAE,0CAA0C;gBACzE,aAAa,EAAE,IAAI,EAAE,yDAAyD;gBAC9E,iEAAiE;gBACjE,GAAG,CAAC,YAAY,GAAG,CAAC,IAAI;oBACtB,QAAQ,EAAE;wBACR,IAAI,EAAE,SAAS;wBACf,YAAY;qBACb;iBACF,CAAC;aACH;SACF,CAAC;QACF,SAAG,CAAC,KAAK,CAAC,mDAAmD,EAAE,OAAO,CAAC,CAAC;QACxE,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,gCAAgC;IAChC,IAAI,QAAQ,KAAK,QAAQ,EAAE,CAAC;QAC1B,MAAM,eAAe,GAAG,kCAAuB,CAAC,iBAAiB,CAAC,CAAC;QAEnE,yEAAyE;QACzE,6CAA6C;QAC7C,mFAAmF;QACnF,yDAAyD;QACzD,4BAA4B;QAC5B,uDAAuD;QACvD,IAAI,kBAAsC,CAAC;QAC3C,IAAI,QAAQ,IAAI,QAAQ,CAAC,MAAM,GAAG,CAAC,IAAI,eAAe,EAAE,CAAC;YACvD,yFAAyF;YACzF,MAAM,gBAAgB,GAAG,IAAA,8BAAqB,EAAC,WAAW,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;YAE1E,kDAAkD;YAClD,KAAK,IAAI,CAAC,GAAG,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC9C,MAAM,GAAG,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;gBACxB,IAAI,GAAG,CAAC,IAAI,KAAK,WAAW,EAAE,CAAC;oBAC7B,+CAA+C;oBAC/C,MAAM,QAAQ,GAAG,GAAG,CAAC,QAAQ,EAAE,KAAK,CAAC;oBACrC,MAAM,YAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,IAAA,8BAAqB,EAAC,QAAQ,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC;oBAE1F,IAAI,YAAY,KAAK,gBAAgB,EAAE,CAAC;wBACtC,MAAM,QAAQ,GAAG,GAAG,CAAC,QAAQ,EAAE,gBAAgB,CAAC;wBAChD,IAAI,QAAQ,IAAI,QAAQ,IAAI,QAAQ,EAAE,CAAC;4BACrC,MAAM,UAAU,GAAG,QAAQ,CAAC,MAA6C,CAAC;4BAC1E,kBAAkB,GAAG,UAAU,EAAE,UAAgC,CAAC;wBACpE,CAAC;wBACD,IAAI,kBAAkB,EAAE,CAAC;4BACvB,0DAA0D;4BAC1D,IAAI,eAAe,EAAE,CAAC,kBAAkB,CAAC,EAAE,CAAC;gCAC1C,SAAG,CAAC,IAAI,CAAC,6DAA6D,EAAE;oCACtE,kBAAkB;oCAClB,KAAK,EAAE,gBAAgB;iCACxB,CAAC,CAAC;gCACH,kBAAkB,GAAG,SAAS,CAAC;4BACjC,CAAC;iCAAM,CAAC;gCACN,SAAG,CAAC,KAAK,CAAC,gEAAgE,EAAE;oCAC1E,kBAAkB;oCAClB,KAAK,EAAE,gBAAgB;iCACxB,CAAC,CAAC;4BACL,CAAC;4BACD,MAAM;wBACR,CAAC;oBACH,CAAC;yBAAM,IAAI,YAAY,EAAE,CAAC;wBACxB,+DAA+D;wBAC/D,SAAG,CAAC,KAAK,CAAC,mEAAmE,EAAE;4BAC7E,aAAa,EAAE,YAAY;4BAC3B,YAAY,EAAE,gBAAgB;yBAC/B,CAAC,CAAC;wBACH,MAAM;oBACR,CAAC;gBACH,CAAC;YACH,CAAC;QACH,CAAC;QAED,4CAA4C;QAC5C,6EAA6E;QAC7E,8EAA8E;QAC9E,MAAM,cAAc,GAAG,WAAW,CAAC,CAAC,CAAC,UAAU,WAAW,EAAE,CAAC,CAAC,CAAC,SAAS,CAAC;QAEzE,MAAM,WAAW,GAAG,kBAAkB,EAAE,MAAM,EAAE,WAAW,IAAI,MAAM,CAAC;QACtE,MAAM,cAAc,GAAG,oBAAoB,IAAI,UAAU,CAAC;QAE1D,SAAG,CAAC,KAAK,CAAC,qCAAqC,EAAE;YAC/C,eAAe;YACf,aAAa,EAAE,iBAAiB;YAChC,kBAAkB;YAClB,cAAc;YACd,UAAU,EAAE,cAAc;SAC3B,CAAC,CAAC;QAEH,MAAM,OAAO,GAAoB;YAC/B,MAAM,EAAE;gBACN,iBAAiB,EAAE,IAAI,EAAE,0CAA0C;gBACnE,WAAW;gBACX,oFAAoF;gBACpF,UAAU,EAAE,cAAc;gBAC1B,4DAA4D;gBAC5D,gFAAgF;gBAChF,GAAG,CAAC,cAAc,IAAI,EAAE,cAAc,EAAE,CAAC;gBACzC,4CAA4C;gBAC5C,GAAG,CAAC,eAAe,IAAI;oBACrB,eAAe;oBACf,gBAAgB,EAAE,UAAU,EAAE,sCAAsC;oBACpE,8FAA8F;oBAC9F,4EAA4E;oBAC5E,gFAAgF;oBAChF,OAAO,EAAE,CAAC,6BAA6B,CAAC;iBACzC,CAAC;gBACF,0DAA0D;gBAC1D,4DAA4D;gBAC5D,GAAG,CAAC,kBAAkB,IAAI,EAAE,kBAAkB,EAAE,CAAC;aAClD;SACF,CAAC;QACF,SAAG,CAAC,IAAI,CAAC,gDAAgD,EAAE,OAAO,CAAC,CAAC;QACpE,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,gCAAgC;IAChC,IAAI,QAAQ,KAAK,QAAQ,EAAE,CAAC;QAC1B,MAAM,SAAS,GAAG,WAAW,CAAC,QAAQ,CAAC,UAAU,CAAC,CAAC;QACnD,IAAI,cAAmE,CAAC;QAExE,IAAI,iBAAiB,KAAK,KAAK,EAAE,CAAC;YAChC,cAAc,GAAG;gBACf,eAAe,EAAE,IAAI;aACtB,CAAC;YAEF,IAAI,SAAS,EAAE,CAAC;gBACd,oEAAoE;gBACpE,iEAAiE;gBACjE,uEAAuE;gBACvE,cAAc,CAAC,aAAa,GAAG,iBAG9B,CAAC;YACJ,CAAC;iBAAM,CAAC;gBACN,iCAAiC;gBACjC,MAAM,MAAM,GAAG,kCAAuB,CAAC,iBAAiB,CAAC,CAAC;gBAC1D,IAAI,MAAM,GAAG,CAAC,EAAE,CAAC;oBACf,cAAc,CAAC,cAAc,GAAG,MAAM,CAAC;gBACzC,CAAC;YACH,CAAC;QACH,CAAC;QAED,MAAM,OAAO,GAAoB;YAC/B,MAAM,EAAE;gBACN,cAAc;aACf;SACF,CAAC;QACF,SAAG,CAAC,KAAK,CAAC,sCAAsC,EAAE,OAAO,CAAC,CAAC;QAC3D,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,oCAAoC;IACpC,IAAI,QAAQ,KAAK,YAAY,EAAE,CAAC;QAC9B,MAAM,eAAe,GAAG,sCAA2B,CAAC,iBAAiB,CAAC,CAAC;QAEvE,SAAG,CAAC,KAAK,CAAC,yCAAyC,EAAE;YACnD,eAAe;YACf,aAAa,EAAE,iBAAiB;SACjC,CAAC,CAAC;QAEH,mDAAmD;QACnD,IAAI,eAAe,EAAE,CAAC;YACpB,MAAM,OAAO,GAAoB;gBAC/B,UAAU,EAAE;oBACV,SAAS,EAAE;wBACT,OAAO,EAAE,IAAI;wBACb,MAAM,EAAE,eAAe;wBACvB,oEAAoE;wBACpE,OAAO,EAAE,KAAK;qBACf;iBACF;aACF,CAAC;YACF,SAAG,CAAC,KAAK,CAAC,oDAAoD,EAAE,OAAO,CAAC,CAAC;YACzE,OAAO,OAAO,CAAC;QACjB,CAAC;QAED,kDAAkD;QAClD,SAAG,CAAC,KAAK,CAAC,sEAAsE,CAAC,CAAC;QAClF,OAAO,EAAE,CAAC;IACZ,CAAC;IAED,6BAA6B;IAC7B,IAAI,QAAQ,KAAK,KAAK,EAAE,CAAC;QACvB,MAAM,SAAS,GAAG,kBAAkB,EAAE,GAAG,IAAI,EAAE,CAAC;QAEhD,MAAM,uBAAuB,GAA2C;YACtE,IAAI,EAAE,MAAM;YACZ,eAAe,EAAE,IAAI;SACtB,CAAC;QAEF,MAAM,OAAO,GAAoB;YAC/B,GAAG,EAAE;gBACH,GAAG,SAAS;gBACZ,gBAAgB,EAAE,SAAS,CAAC,gBAAgB,IAAI,uBAAuB;aACxE;SACF,CAAC;QACF,SAAG,CAAC,KAAK,CAAC,6CAA6C,EAAE,OAAO,CAAC,CAAC;QAClE,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,yDAAyD;IACzD,SAAG,CAAC,KAAK,CAAC,4CAA4C,EAAE,QAAQ,CAAC,CAAC;IAClE,OAAO,EAAE,CAAC;AAAA,CACX","sourcesContent":["/**\r\n * Provider options builder for AI SDK\r\n *\r\n * Converts unified thinking levels to provider-specific options\r\n */\r\n\r\nimport type { AnthropicProviderOptions } from \"@ai-sdk/anthropic\";\r\nimport type { OpenAIResponsesProviderOptions } from \"@ai-sdk/openai\";\r\nimport type { GoogleGenerativeAIProviderOptions } from \"@ai-sdk/google\";\r\nimport type { XaiProviderOptions } from \"@ai-sdk/xai\";\r\nimport type { MuxProviderOptions } from \"@/common/types/providerOptions\";\r\nimport type { ThinkingLevel } from \"@/common/types/thinking\";\r\nimport {\r\n  getAnthropicEffort,\r\n  ANTHROPIC_THINKING_BUDGETS,\r\n  GEMINI_THINKING_BUDGETS,\r\n  OPENAI_REASONING_EFFORT,\r\n  OPENROUTER_REASONING_EFFORT,\r\n} from \"@/common/types/thinking\";\r\nimport { log } from \"@/node/services/log\";\r\nimport type { MuxMessage } from \"@/common/types/message\";\r\nimport { normalizeGatewayModel } from \"./models\";\r\n\r\n/**\r\n * OpenRouter reasoning options\r\n * @see https://openrouter.ai/docs/use-cases/reasoning-tokens\r\n */\r\ninterface OpenRouterReasoningOptions {\r\n  reasoning?: {\r\n    enabled?: boolean;\r\n    exclude?: boolean;\r\n    effort?: \"low\" | \"medium\" | \"high\";\r\n  };\r\n}\r\n\r\n/**\r\n * Provider-specific options structure for AI SDK\r\n */\r\ntype ProviderOptions =\r\n  | { anthropic: AnthropicProviderOptions }\r\n  | { openai: OpenAIResponsesProviderOptions }\r\n  | { google: GoogleGenerativeAIProviderOptions }\r\n  | { openrouter: OpenRouterReasoningOptions }\r\n  | { xai: XaiProviderOptions }\r\n  | Record<string, never>; // Empty object for unsupported providers\r\n\r\n/**\r\n * Build provider-specific options for AI SDK based on thinking level\r\n *\r\n * This function configures provider-specific options for supported providers:\r\n * 1. Enable reasoning traces (transparency into model's thought process)\r\n * 2. Set reasoning level (control depth of reasoning based on task complexity)\r\n * 3. Enable parallel tool calls (allow concurrent tool execution)\r\n * 4. Extract previousResponseId for OpenAI persistence (when available)\r\n *\r\n * @param modelString - Full model string (e.g., \"anthropic:claude-opus-4-1\")\r\n * @param thinkingLevel - Unified thinking level (must be pre-clamped via enforceThinkingPolicy)\r\n * @param messages - Conversation history to extract previousResponseId from\r\n * @param lostResponseIds - Optional callback to check if a responseId has been invalidated by OpenAI\r\n * @param muxProviderOptions - Optional provider overrides from config\r\n * @param workspaceId - Optional for non-OpenAI providers\r\n * @param openaiTruncationMode - Optional truncation mode for OpenAI responses (auto/disabled)\r\n * @returns Provider options object for AI SDK\r\n */\r\nexport function buildProviderOptions(\r\n  modelString: string,\r\n  thinkingLevel: ThinkingLevel,\r\n  messages?: MuxMessage[],\r\n  lostResponseIds?: (id: string) => boolean,\r\n  muxProviderOptions?: MuxProviderOptions,\r\n  workspaceId?: string, // Optional for non-OpenAI providers\r\n  openaiTruncationMode?: OpenAIResponsesProviderOptions[\"truncation\"]\r\n): ProviderOptions {\r\n  // Caller is responsible for enforcing thinking policy before calling this function.\r\n  // agentSession.ts is the canonical enforcement point.\r\n  const effectiveThinking = thinkingLevel;\r\n  // Parse provider from normalized model string\r\n  const [provider, modelName] = normalizeGatewayModel(modelString).split(\":\", 2);\r\n\r\n  log.debug(\"buildProviderOptions\", {\r\n    modelString,\r\n    provider,\r\n    modelName,\r\n    thinkingLevel,\r\n  });\r\n\r\n  if (!provider || !modelName) {\r\n    log.debug(\"buildProviderOptions: No provider or model name found, returning empty\");\r\n    return {};\r\n  }\r\n\r\n  // Build Anthropic-specific options\r\n  if (provider === \"anthropic\") {\r\n    // Opus 4.5+ use the effort parameter for reasoning control.\r\n    // Opus 4.6 uses adaptive thinking (model decides when/how much to think).\r\n    // Opus 4.5 uses enabled thinking with a budgetTokens ceiling.\r\n    const isOpus45 = modelName?.includes(\"opus-4-5\") ?? false;\r\n    const isOpus46 = modelName?.includes(\"opus-4-6\") ?? false;\r\n\r\n    if (isOpus45 || isOpus46) {\r\n      // xhigh maps to \"max\" effort; policy clamps Opus 4.5 to \"high\" max\r\n      const effortLevel = getAnthropicEffort(effectiveThinking);\r\n      const budgetTokens = ANTHROPIC_THINKING_BUDGETS[effectiveThinking];\r\n      // Opus 4.6: adaptive thinking when on, disabled when off\r\n      // Opus 4.5: enabled thinking with budgetTokens ceiling (only when not \"off\")\r\n      const thinking: AnthropicProviderOptions[\"thinking\"] = isOpus46\r\n        ? effectiveThinking === \"off\"\r\n          ? { type: \"disabled\" }\r\n          : { type: \"adaptive\" }\r\n        : budgetTokens > 0\r\n          ? { type: \"enabled\", budgetTokens }\r\n          : undefined;\r\n\r\n      log.debug(\"buildProviderOptions: Anthropic effort model config\", {\r\n        effort: effortLevel,\r\n        thinking,\r\n        thinkingLevel: effectiveThinking,\r\n      });\r\n\r\n      return {\r\n        anthropic: {\r\n          disableParallelToolUse: false,\r\n          sendReasoning: true,\r\n          ...(thinking && { thinking }),\r\n          effort: effortLevel,\r\n        },\r\n      };\r\n    }\r\n\r\n    // Other Anthropic models: Use thinking parameter with budgetTokens\r\n    const budgetTokens = ANTHROPIC_THINKING_BUDGETS[effectiveThinking];\r\n    log.debug(\"buildProviderOptions: Anthropic config\", {\r\n      budgetTokens,\r\n      thinkingLevel: effectiveThinking,\r\n    });\r\n\r\n    const options: ProviderOptions = {\r\n      anthropic: {\r\n        disableParallelToolUse: false, // Always enable concurrent tool execution\r\n        sendReasoning: true, // Include reasoning traces in requests sent to the model\r\n        // Conditionally add thinking configuration (non-Opus 4.5 models)\r\n        ...(budgetTokens > 0 && {\r\n          thinking: {\r\n            type: \"enabled\",\r\n            budgetTokens,\r\n          },\r\n        }),\r\n      },\r\n    };\r\n    log.debug(\"buildProviderOptions: Returning Anthropic options\", options);\r\n    return options;\r\n  }\r\n\r\n  // Build OpenAI-specific options\r\n  if (provider === \"openai\") {\r\n    const reasoningEffort = OPENAI_REASONING_EFFORT[effectiveThinking];\r\n\r\n    // Extract previousResponseId from last assistant message for persistence\r\n    // IMPORTANT: Only use previousResponseId if:\r\n    // 1. The previous message used the same model (prevents cross-model contamination)\r\n    // 2. That model uses reasoning (reasoning effort is set)\r\n    // 3. The response ID exists\r\n    // 4. The response ID hasn't been invalidated by OpenAI\r\n    let previousResponseId: string | undefined;\r\n    if (messages && messages.length > 0 && reasoningEffort) {\r\n      // Parse current model name (without provider prefix), normalize gateway format if needed\r\n      const currentModelName = normalizeGatewayModel(modelString).split(\":\")[1];\r\n\r\n      // Find last assistant message from the same model\r\n      for (let i = messages.length - 1; i >= 0; i--) {\r\n        const msg = messages[i];\r\n        if (msg.role === \"assistant\") {\r\n          // Check if this message is from the same model\r\n          const msgModel = msg.metadata?.model;\r\n          const msgModelName = msgModel ? normalizeGatewayModel(msgModel).split(\":\")[1] : undefined;\r\n\r\n          if (msgModelName === currentModelName) {\r\n            const metadata = msg.metadata?.providerMetadata;\r\n            if (metadata && \"openai\" in metadata) {\r\n              const openaiData = metadata.openai as Record<string, unknown> | undefined;\r\n              previousResponseId = openaiData?.responseId as string | undefined;\r\n            }\r\n            if (previousResponseId) {\r\n              // Check if this responseId has been invalidated by OpenAI\r\n              if (lostResponseIds?.(previousResponseId)) {\r\n                log.info(\"buildProviderOptions: Filtering out lost previousResponseId\", {\r\n                  previousResponseId,\r\n                  model: currentModelName,\r\n                });\r\n                previousResponseId = undefined;\r\n              } else {\r\n                log.debug(\"buildProviderOptions: Found previousResponseId from same model\", {\r\n                  previousResponseId,\r\n                  model: currentModelName,\r\n                });\r\n              }\r\n              break;\r\n            }\r\n          } else if (msgModelName) {\r\n            // Found assistant message from different model, stop searching\r\n            log.debug(\"buildProviderOptions: Skipping previousResponseId - model changed\", {\r\n              previousModel: msgModelName,\r\n              currentModel: currentModelName,\r\n            });\r\n            break;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    // Prompt cache key: derive from workspaceId\r\n    // This helps OpenAI route requests to cached prefixes for improved hit rates\r\n    // workspaceId is always passed from AIService.streamMessage for real requests\r\n    const promptCacheKey = workspaceId ? `mux-v1-${workspaceId}` : undefined;\r\n\r\n    const serviceTier = muxProviderOptions?.openai?.serviceTier ?? \"auto\";\r\n    const truncationMode = openaiTruncationMode ?? \"disabled\";\r\n\r\n    log.debug(\"buildProviderOptions: OpenAI config\", {\r\n      reasoningEffort,\r\n      thinkingLevel: effectiveThinking,\r\n      previousResponseId,\r\n      promptCacheKey,\r\n      truncation: truncationMode,\r\n    });\r\n\r\n    const options: ProviderOptions = {\r\n      openai: {\r\n        parallelToolCalls: true, // Always enable concurrent tool execution\r\n        serviceTier,\r\n        // Default to disabled; allow auto truncation for compaction to avoid context errors\r\n        truncation: truncationMode,\r\n        // Stable prompt cache key to improve OpenAI cache hit rates\r\n        // See: https://sdk.vercel.ai/providers/ai-sdk-providers/openai#responses-models\r\n        ...(promptCacheKey && { promptCacheKey }),\r\n        // Conditionally add reasoning configuration\r\n        ...(reasoningEffort && {\r\n          reasoningEffort,\r\n          reasoningSummary: \"detailed\", // Enable detailed reasoning summaries\r\n          // Include reasoning encrypted content to preserve reasoning context across conversation steps\r\n          // Required when using reasoning models (gpt-5, o3, o4-mini) with tool calls\r\n          // See: https://sdk.vercel.ai/providers/ai-sdk-providers/openai#responses-models\r\n          include: [\"reasoning.encrypted_content\"],\r\n        }),\r\n        // Include previousResponseId for conversation persistence\r\n        // OpenAI uses this to maintain reasoning state across turns\r\n        ...(previousResponseId && { previousResponseId }),\r\n      },\r\n    };\r\n    log.info(\"buildProviderOptions: Returning OpenAI options\", options);\r\n    return options;\r\n  }\r\n\r\n  // Build Google-specific options\r\n  if (provider === \"google\") {\r\n    const isGemini3 = modelString.includes(\"gemini-3\");\r\n    let thinkingConfig: GoogleGenerativeAIProviderOptions[\"thinkingConfig\"];\r\n\r\n    if (effectiveThinking !== \"off\") {\r\n      thinkingConfig = {\r\n        includeThoughts: true,\r\n      };\r\n\r\n      if (isGemini3) {\r\n        // Policy enforcement already clamped to valid levels for Flash/Pro,\r\n        // so effectiveThinking is guaranteed in the model's allowed set.\r\n        // Flash: off/low/medium/high; Pro: low/high. \"xhigh\" can't reach here.\r\n        thinkingConfig.thinkingLevel = effectiveThinking as Exclude<\r\n          ThinkingLevel,\r\n          \"off\" | \"xhigh\" | \"max\"\r\n        >;\r\n      } else {\r\n        // Gemini 2.5 uses thinkingBudget\r\n        const budget = GEMINI_THINKING_BUDGETS[effectiveThinking];\r\n        if (budget > 0) {\r\n          thinkingConfig.thinkingBudget = budget;\r\n        }\r\n      }\r\n    }\r\n\r\n    const options: ProviderOptions = {\r\n      google: {\r\n        thinkingConfig,\r\n      },\r\n    };\r\n    log.debug(\"buildProviderOptions: Google options\", options);\r\n    return options;\r\n  }\r\n\r\n  // Build OpenRouter-specific options\r\n  if (provider === \"openrouter\") {\r\n    const reasoningEffort = OPENROUTER_REASONING_EFFORT[effectiveThinking];\r\n\r\n    log.debug(\"buildProviderOptions: OpenRouter config\", {\r\n      reasoningEffort,\r\n      thinkingLevel: effectiveThinking,\r\n    });\r\n\r\n    // Only add reasoning config if thinking is enabled\r\n    if (reasoningEffort) {\r\n      const options: ProviderOptions = {\r\n        openrouter: {\r\n          reasoning: {\r\n            enabled: true,\r\n            effort: reasoningEffort,\r\n            // Don't exclude reasoning content - we want to display it in the UI\r\n            exclude: false,\r\n          },\r\n        },\r\n      };\r\n      log.debug(\"buildProviderOptions: Returning OpenRouter options\", options);\r\n      return options;\r\n    }\r\n\r\n    // No reasoning config needed when thinking is off\r\n    log.debug(\"buildProviderOptions: OpenRouter (thinking off, no provider options)\");\r\n    return {};\r\n  }\r\n\r\n  // Build xAI-specific options\r\n  if (provider === \"xai\") {\r\n    const overrides = muxProviderOptions?.xai ?? {};\r\n\r\n    const defaultSearchParameters: XaiProviderOptions[\"searchParameters\"] = {\r\n      mode: \"auto\",\r\n      returnCitations: true,\r\n    };\r\n\r\n    const options: ProviderOptions = {\r\n      xai: {\r\n        ...overrides,\r\n        searchParameters: overrides.searchParameters ?? defaultSearchParameters,\r\n      },\r\n    };\r\n    log.debug(\"buildProviderOptions: Returning xAI options\", options);\r\n    return options;\r\n  }\r\n\r\n  // No provider-specific options for unsupported providers\r\n  log.debug(\"buildProviderOptions: Unsupported provider\", provider);\r\n  return {};\r\n}\r\n"]}