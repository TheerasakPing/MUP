{"version":3,"file":"providerOptions.js","sourceRoot":"","sources":["../../../../src/common/utils/ai/providerOptions.ts"],"names":[],"mappings":";AAAA;;;;GAIG;;;AAQH,sDAMiC;AACjC,6CAA0C;AAE1C,qCAAiD;AAyBjD;;;;;;;;;;;;;;;;;GAiBG;AACH,8BACE,WAAmB,EACnB,aAA4B,EAC5B,QAAuB,EACvB,eAAyC,EACzC,kBAAuC,EACvC,WAAoB,EAAE,oCAAoC;AAC1D,oBAAmE,EAClD;IACjB,oFAAoF;IACpF,sDAAsD;IACtD,MAAM,iBAAiB,GAAG,aAAa,CAAC;IACxC,8CAA8C;IAC9C,MAAM,CAAC,QAAQ,EAAE,SAAS,CAAC,GAAG,IAAA,8BAAqB,EAAC,WAAW,CAAC,CAAC,KAAK,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC;IAE/E,SAAG,CAAC,KAAK,CAAC,sBAAsB,EAAE;QAChC,WAAW;QACX,QAAQ;QACR,SAAS;QACT,aAAa;KACd,CAAC,CAAC;IAEH,IAAI,CAAC,QAAQ,IAAI,CAAC,SAAS,EAAE,CAAC;QAC5B,SAAG,CAAC,KAAK,CAAC,wEAAwE,CAAC,CAAC;QACpF,OAAO,EAAE,CAAC;IACZ,CAAC;IAED,mCAAmC;IACnC,IAAI,QAAQ,KAAK,WAAW,EAAE,CAAC;QAC7B,4DAA4D;QAC5D,0EAA0E;QAC1E,8DAA8D;QAC9D,MAAM,QAAQ,GAAG,SAAS,EAAE,QAAQ,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC;QAC1D,MAAM,QAAQ,GAAG,SAAS,EAAE,QAAQ,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC;QAE1D,IAAI,QAAQ,IAAI,QAAQ,EAAE,CAAC;YACzB,mEAAmE;YACnE,MAAM,WAAW,GAAG,IAAA,6BAAkB,EAAC,iBAAiB,CAAC,CAAC;YAC1D,MAAM,YAAY,GAAG,qCAA0B,CAAC,iBAAiB,CAAC,CAAC;YACnE,yDAAyD;YACzD,6EAA6E;YAC7E,MAAM,QAAQ,GAAyC,QAAQ;gBAC7D,CAAC,CAAC,iBAAiB,KAAK,KAAK;oBAC3B,CAAC,CAAC,EAAE,IAAI,EAAE,UAAU,EAAE;oBACtB,CAAC,CAAC,EAAE,IAAI,EAAE,UAAU,EAAE;gBACxB,CAAC,CAAC,YAAY,GAAG,CAAC;oBAChB,CAAC,CAAC,EAAE,IAAI,EAAE,SAAS,EAAE,YAAY,EAAE;oBACnC,CAAC,CAAC,SAAS,CAAC;YAEhB,SAAG,CAAC,KAAK,CAAC,qDAAqD,EAAE;gBAC/D,MAAM,EAAE,WAAW;gBACnB,QAAQ;gBACR,aAAa,EAAE,iBAAiB;aACjC,CAAC,CAAC;YAEH,OAAO;gBACL,SAAS,EAAE;oBACT,sBAAsB,EAAE,KAAK;oBAC7B,aAAa,EAAE,IAAI;oBACnB,GAAG,CAAC,QAAQ,IAAI,EAAE,QAAQ,EAAE,CAAC;oBAC7B,MAAM,EAAE,WAAW;iBACpB;aACF,CAAC;QACJ,CAAC;QAED,mEAAmE;QACnE,MAAM,YAAY,GAAG,qCAA0B,CAAC,iBAAiB,CAAC,CAAC;QACnE,SAAG,CAAC,KAAK,CAAC,wCAAwC,EAAE;YAClD,YAAY;YACZ,aAAa,EAAE,iBAAiB;SACjC,CAAC,CAAC;QAEH,MAAM,OAAO,GAAoB;YAC/B,SAAS,EAAE;gBACT,sBAAsB,EAAE,KAAK,EAAE,0CAA0C;gBACzE,aAAa,EAAE,IAAI,EAAE,yDAAyD;gBAC9E,iEAAiE;gBACjE,GAAG,CAAC,YAAY,GAAG,CAAC,IAAI;oBACtB,QAAQ,EAAE;wBACR,IAAI,EAAE,SAAS;wBACf,YAAY;qBACb;iBACF,CAAC;aACH;SACF,CAAC;QACF,SAAG,CAAC,KAAK,CAAC,mDAAmD,EAAE,OAAO,CAAC,CAAC;QACxE,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,gCAAgC;IAChC,IAAI,QAAQ,KAAK,QAAQ,EAAE,CAAC;QAC1B,MAAM,eAAe,GAAG,kCAAuB,CAAC,iBAAiB,CAAC,CAAC;QAEnE,yEAAyE;QACzE,6CAA6C;QAC7C,mFAAmF;QACnF,yDAAyD;QACzD,4BAA4B;QAC5B,uDAAuD;QACvD,IAAI,kBAAsC,CAAC;QAC3C,IAAI,QAAQ,IAAI,QAAQ,CAAC,MAAM,GAAG,CAAC,IAAI,eAAe,EAAE,CAAC;YACvD,yFAAyF;YACzF,MAAM,gBAAgB,GAAG,IAAA,8BAAqB,EAAC,WAAW,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;YAE1E,kDAAkD;YAClD,KAAK,IAAI,CAAC,GAAG,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC9C,MAAM,GAAG,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;gBACxB,IAAI,GAAG,CAAC,IAAI,KAAK,WAAW,EAAE,CAAC;oBAC7B,+CAA+C;oBAC/C,MAAM,QAAQ,GAAG,GAAG,CAAC,QAAQ,EAAE,KAAK,CAAC;oBACrC,MAAM,YAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,IAAA,8BAAqB,EAAC,QAAQ,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC;oBAE1F,IAAI,YAAY,KAAK,gBAAgB,EAAE,CAAC;wBACtC,MAAM,QAAQ,GAAG,GAAG,CAAC,QAAQ,EAAE,gBAAgB,CAAC;wBAChD,IAAI,QAAQ,IAAI,QAAQ,IAAI,QAAQ,EAAE,CAAC;4BACrC,MAAM,UAAU,GAAG,QAAQ,CAAC,MAA6C,CAAC;4BAC1E,kBAAkB,GAAG,UAAU,EAAE,UAAgC,CAAC;wBACpE,CAAC;wBACD,IAAI,kBAAkB,EAAE,CAAC;4BACvB,0DAA0D;4BAC1D,IAAI,eAAe,EAAE,CAAC,kBAAkB,CAAC,EAAE,CAAC;gCAC1C,SAAG,CAAC,IAAI,CAAC,6DAA6D,EAAE;oCACtE,kBAAkB;oCAClB,KAAK,EAAE,gBAAgB;iCACxB,CAAC,CAAC;gCACH,kBAAkB,GAAG,SAAS,CAAC;4BACjC,CAAC;iCAAM,CAAC;gCACN,SAAG,CAAC,KAAK,CAAC,gEAAgE,EAAE;oCAC1E,kBAAkB;oCAClB,KAAK,EAAE,gBAAgB;iCACxB,CAAC,CAAC;4BACL,CAAC;4BACD,MAAM;wBACR,CAAC;oBACH,CAAC;yBAAM,IAAI,YAAY,EAAE,CAAC;wBACxB,+DAA+D;wBAC/D,SAAG,CAAC,KAAK,CAAC,mEAAmE,EAAE;4BAC7E,aAAa,EAAE,YAAY;4BAC3B,YAAY,EAAE,gBAAgB;yBAC/B,CAAC,CAAC;wBACH,MAAM;oBACR,CAAC;gBACH,CAAC;YACH,CAAC;QACH,CAAC;QAED,4CAA4C;QAC5C,6EAA6E;QAC7E,8EAA8E;QAC9E,MAAM,cAAc,GAAG,WAAW,CAAC,CAAC,CAAC,UAAU,WAAW,EAAE,CAAC,CAAC,CAAC,SAAS,CAAC;QAEzE,MAAM,WAAW,GAAG,kBAAkB,EAAE,MAAM,EAAE,WAAW,IAAI,MAAM,CAAC;QACtE,MAAM,cAAc,GAAG,oBAAoB,IAAI,UAAU,CAAC;QAE1D,SAAG,CAAC,KAAK,CAAC,qCAAqC,EAAE;YAC/C,eAAe;YACf,aAAa,EAAE,iBAAiB;YAChC,kBAAkB;YAClB,cAAc;YACd,UAAU,EAAE,cAAc;SAC3B,CAAC,CAAC;QAEH,MAAM,OAAO,GAAoB;YAC/B,MAAM,EAAE;gBACN,iBAAiB,EAAE,IAAI,EAAE,0CAA0C;gBACnE,WAAW;gBACX,oFAAoF;gBACpF,UAAU,EAAE,cAAc;gBAC1B,4DAA4D;gBAC5D,gFAAgF;gBAChF,GAAG,CAAC,cAAc,IAAI,EAAE,cAAc,EAAE,CAAC;gBACzC,4CAA4C;gBAC5C,GAAG,CAAC,eAAe,IAAI;oBACrB,eAAe;oBACf,gBAAgB,EAAE,UAAU,EAAE,sCAAsC;oBACpE,8FAA8F;oBAC9F,4EAA4E;oBAC5E,gFAAgF;oBAChF,OAAO,EAAE,CAAC,6BAA6B,CAAC;iBACzC,CAAC;gBACF,0DAA0D;gBAC1D,4DAA4D;gBAC5D,GAAG,CAAC,kBAAkB,IAAI,EAAE,kBAAkB,EAAE,CAAC;aAClD;SACF,CAAC;QACF,SAAG,CAAC,IAAI,CAAC,gDAAgD,EAAE,OAAO,CAAC,CAAC;QACpE,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,gCAAgC;IAChC,IAAI,QAAQ,KAAK,QAAQ,EAAE,CAAC;QAC1B,MAAM,SAAS,GAAG,WAAW,CAAC,QAAQ,CAAC,UAAU,CAAC,CAAC;QACnD,IAAI,cAAmE,CAAC;QAExE,IAAI,iBAAiB,KAAK,KAAK,EAAE,CAAC;YAChC,cAAc,GAAG;gBACf,eAAe,EAAE,IAAI;aACtB,CAAC;YAEF,IAAI,SAAS,EAAE,CAAC;gBACd,oEAAoE;gBACpE,iEAAiE;gBACjE,uEAAuE;gBACvE,cAAc,CAAC,aAAa,GAAG,iBAG9B,CAAC;YACJ,CAAC;iBAAM,CAAC;gBACN,iCAAiC;gBACjC,MAAM,MAAM,GAAG,kCAAuB,CAAC,iBAAiB,CAAC,CAAC;gBAC1D,IAAI,MAAM,GAAG,CAAC,EAAE,CAAC;oBACf,cAAc,CAAC,cAAc,GAAG,MAAM,CAAC;gBACzC,CAAC;YACH,CAAC;QACH,CAAC;QAED,MAAM,OAAO,GAAoB;YAC/B,MAAM,EAAE;gBACN,cAAc;aACf;SACF,CAAC;QACF,SAAG,CAAC,KAAK,CAAC,sCAAsC,EAAE,OAAO,CAAC,CAAC;QAC3D,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,oCAAoC;IACpC,IAAI,QAAQ,KAAK,YAAY,EAAE,CAAC;QAC9B,MAAM,eAAe,GAAG,sCAA2B,CAAC,iBAAiB,CAAC,CAAC;QAEvE,SAAG,CAAC,KAAK,CAAC,yCAAyC,EAAE;YACnD,eAAe;YACf,aAAa,EAAE,iBAAiB;SACjC,CAAC,CAAC;QAEH,mDAAmD;QACnD,IAAI,eAAe,EAAE,CAAC;YACpB,MAAM,OAAO,GAAoB;gBAC/B,UAAU,EAAE;oBACV,SAAS,EAAE;wBACT,OAAO,EAAE,IAAI;wBACb,MAAM,EAAE,eAAe;wBACvB,oEAAoE;wBACpE,OAAO,EAAE,KAAK;qBACf;iBACF;aACF,CAAC;YACF,SAAG,CAAC,KAAK,CAAC,oDAAoD,EAAE,OAAO,CAAC,CAAC;YACzE,OAAO,OAAO,CAAC;QACjB,CAAC;QAED,kDAAkD;QAClD,SAAG,CAAC,KAAK,CAAC,sEAAsE,CAAC,CAAC;QAClF,OAAO,EAAE,CAAC;IACZ,CAAC;IAED,6BAA6B;IAC7B,IAAI,QAAQ,KAAK,KAAK,EAAE,CAAC;QACvB,MAAM,SAAS,GAAG,kBAAkB,EAAE,GAAG,IAAI,EAAE,CAAC;QAEhD,MAAM,uBAAuB,GAA2C;YACtE,IAAI,EAAE,MAAM;YACZ,eAAe,EAAE,IAAI;SACtB,CAAC;QAEF,MAAM,OAAO,GAAoB;YAC/B,GAAG,EAAE;gBACH,GAAG,SAAS;gBACZ,gBAAgB,EAAE,SAAS,CAAC,gBAAgB,IAAI,uBAAuB;aACxE;SACF,CAAC;QACF,SAAG,CAAC,KAAK,CAAC,6CAA6C,EAAE,OAAO,CAAC,CAAC;QAClE,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,yDAAyD;IACzD,SAAG,CAAC,KAAK,CAAC,4CAA4C,EAAE,QAAQ,CAAC,CAAC;IAClE,OAAO,EAAE,CAAC;AAAA,CACX","sourcesContent":["/**\n * Provider options builder for AI SDK\n *\n * Converts unified thinking levels to provider-specific options\n */\n\nimport type { AnthropicProviderOptions } from \"@ai-sdk/anthropic\";\nimport type { OpenAIResponsesProviderOptions } from \"@ai-sdk/openai\";\nimport type { GoogleGenerativeAIProviderOptions } from \"@ai-sdk/google\";\nimport type { XaiProviderOptions } from \"@ai-sdk/xai\";\nimport type { MuxProviderOptions } from \"@/common/types/providerOptions\";\nimport type { ThinkingLevel } from \"@/common/types/thinking\";\nimport {\n  getAnthropicEffort,\n  ANTHROPIC_THINKING_BUDGETS,\n  GEMINI_THINKING_BUDGETS,\n  OPENAI_REASONING_EFFORT,\n  OPENROUTER_REASONING_EFFORT,\n} from \"@/common/types/thinking\";\nimport { log } from \"@/node/services/log\";\nimport type { MuxMessage } from \"@/common/types/message\";\nimport { normalizeGatewayModel } from \"./models\";\n\n/**\n * OpenRouter reasoning options\n * @see https://openrouter.ai/docs/use-cases/reasoning-tokens\n */\ninterface OpenRouterReasoningOptions {\n  reasoning?: {\n    enabled?: boolean;\n    exclude?: boolean;\n    effort?: \"low\" | \"medium\" | \"high\";\n  };\n}\n\n/**\n * Provider-specific options structure for AI SDK\n */\ntype ProviderOptions =\n  | { anthropic: AnthropicProviderOptions }\n  | { openai: OpenAIResponsesProviderOptions }\n  | { google: GoogleGenerativeAIProviderOptions }\n  | { openrouter: OpenRouterReasoningOptions }\n  | { xai: XaiProviderOptions }\n  | Record<string, never>; // Empty object for unsupported providers\n\n/**\n * Build provider-specific options for AI SDK based on thinking level\n *\n * This function configures provider-specific options for supported providers:\n * 1. Enable reasoning traces (transparency into model's thought process)\n * 2. Set reasoning level (control depth of reasoning based on task complexity)\n * 3. Enable parallel tool calls (allow concurrent tool execution)\n * 4. Extract previousResponseId for OpenAI persistence (when available)\n *\n * @param modelString - Full model string (e.g., \"anthropic:claude-opus-4-1\")\n * @param thinkingLevel - Unified thinking level (must be pre-clamped via enforceThinkingPolicy)\n * @param messages - Conversation history to extract previousResponseId from\n * @param lostResponseIds - Optional callback to check if a responseId has been invalidated by OpenAI\n * @param muxProviderOptions - Optional provider overrides from config\n * @param workspaceId - Optional for non-OpenAI providers\n * @param openaiTruncationMode - Optional truncation mode for OpenAI responses (auto/disabled)\n * @returns Provider options object for AI SDK\n */\nexport function buildProviderOptions(\n  modelString: string,\n  thinkingLevel: ThinkingLevel,\n  messages?: MuxMessage[],\n  lostResponseIds?: (id: string) => boolean,\n  muxProviderOptions?: MuxProviderOptions,\n  workspaceId?: string, // Optional for non-OpenAI providers\n  openaiTruncationMode?: OpenAIResponsesProviderOptions[\"truncation\"]\n): ProviderOptions {\n  // Caller is responsible for enforcing thinking policy before calling this function.\n  // agentSession.ts is the canonical enforcement point.\n  const effectiveThinking = thinkingLevel;\n  // Parse provider from normalized model string\n  const [provider, modelName] = normalizeGatewayModel(modelString).split(\":\", 2);\n\n  log.debug(\"buildProviderOptions\", {\n    modelString,\n    provider,\n    modelName,\n    thinkingLevel,\n  });\n\n  if (!provider || !modelName) {\n    log.debug(\"buildProviderOptions: No provider or model name found, returning empty\");\n    return {};\n  }\n\n  // Build Anthropic-specific options\n  if (provider === \"anthropic\") {\n    // Opus 4.5+ use the effort parameter for reasoning control.\n    // Opus 4.6 uses adaptive thinking (model decides when/how much to think).\n    // Opus 4.5 uses enabled thinking with a budgetTokens ceiling.\n    const isOpus45 = modelName?.includes(\"opus-4-5\") ?? false;\n    const isOpus46 = modelName?.includes(\"opus-4-6\") ?? false;\n\n    if (isOpus45 || isOpus46) {\n      // xhigh maps to \"max\" effort; policy clamps Opus 4.5 to \"high\" max\n      const effortLevel = getAnthropicEffort(effectiveThinking);\n      const budgetTokens = ANTHROPIC_THINKING_BUDGETS[effectiveThinking];\n      // Opus 4.6: adaptive thinking when on, disabled when off\n      // Opus 4.5: enabled thinking with budgetTokens ceiling (only when not \"off\")\n      const thinking: AnthropicProviderOptions[\"thinking\"] = isOpus46\n        ? effectiveThinking === \"off\"\n          ? { type: \"disabled\" }\n          : { type: \"adaptive\" }\n        : budgetTokens > 0\n          ? { type: \"enabled\", budgetTokens }\n          : undefined;\n\n      log.debug(\"buildProviderOptions: Anthropic effort model config\", {\n        effort: effortLevel,\n        thinking,\n        thinkingLevel: effectiveThinking,\n      });\n\n      return {\n        anthropic: {\n          disableParallelToolUse: false,\n          sendReasoning: true,\n          ...(thinking && { thinking }),\n          effort: effortLevel,\n        },\n      };\n    }\n\n    // Other Anthropic models: Use thinking parameter with budgetTokens\n    const budgetTokens = ANTHROPIC_THINKING_BUDGETS[effectiveThinking];\n    log.debug(\"buildProviderOptions: Anthropic config\", {\n      budgetTokens,\n      thinkingLevel: effectiveThinking,\n    });\n\n    const options: ProviderOptions = {\n      anthropic: {\n        disableParallelToolUse: false, // Always enable concurrent tool execution\n        sendReasoning: true, // Include reasoning traces in requests sent to the model\n        // Conditionally add thinking configuration (non-Opus 4.5 models)\n        ...(budgetTokens > 0 && {\n          thinking: {\n            type: \"enabled\",\n            budgetTokens,\n          },\n        }),\n      },\n    };\n    log.debug(\"buildProviderOptions: Returning Anthropic options\", options);\n    return options;\n  }\n\n  // Build OpenAI-specific options\n  if (provider === \"openai\") {\n    const reasoningEffort = OPENAI_REASONING_EFFORT[effectiveThinking];\n\n    // Extract previousResponseId from last assistant message for persistence\n    // IMPORTANT: Only use previousResponseId if:\n    // 1. The previous message used the same model (prevents cross-model contamination)\n    // 2. That model uses reasoning (reasoning effort is set)\n    // 3. The response ID exists\n    // 4. The response ID hasn't been invalidated by OpenAI\n    let previousResponseId: string | undefined;\n    if (messages && messages.length > 0 && reasoningEffort) {\n      // Parse current model name (without provider prefix), normalize gateway format if needed\n      const currentModelName = normalizeGatewayModel(modelString).split(\":\")[1];\n\n      // Find last assistant message from the same model\n      for (let i = messages.length - 1; i >= 0; i--) {\n        const msg = messages[i];\n        if (msg.role === \"assistant\") {\n          // Check if this message is from the same model\n          const msgModel = msg.metadata?.model;\n          const msgModelName = msgModel ? normalizeGatewayModel(msgModel).split(\":\")[1] : undefined;\n\n          if (msgModelName === currentModelName) {\n            const metadata = msg.metadata?.providerMetadata;\n            if (metadata && \"openai\" in metadata) {\n              const openaiData = metadata.openai as Record<string, unknown> | undefined;\n              previousResponseId = openaiData?.responseId as string | undefined;\n            }\n            if (previousResponseId) {\n              // Check if this responseId has been invalidated by OpenAI\n              if (lostResponseIds?.(previousResponseId)) {\n                log.info(\"buildProviderOptions: Filtering out lost previousResponseId\", {\n                  previousResponseId,\n                  model: currentModelName,\n                });\n                previousResponseId = undefined;\n              } else {\n                log.debug(\"buildProviderOptions: Found previousResponseId from same model\", {\n                  previousResponseId,\n                  model: currentModelName,\n                });\n              }\n              break;\n            }\n          } else if (msgModelName) {\n            // Found assistant message from different model, stop searching\n            log.debug(\"buildProviderOptions: Skipping previousResponseId - model changed\", {\n              previousModel: msgModelName,\n              currentModel: currentModelName,\n            });\n            break;\n          }\n        }\n      }\n    }\n\n    // Prompt cache key: derive from workspaceId\n    // This helps OpenAI route requests to cached prefixes for improved hit rates\n    // workspaceId is always passed from AIService.streamMessage for real requests\n    const promptCacheKey = workspaceId ? `mux-v1-${workspaceId}` : undefined;\n\n    const serviceTier = muxProviderOptions?.openai?.serviceTier ?? \"auto\";\n    const truncationMode = openaiTruncationMode ?? \"disabled\";\n\n    log.debug(\"buildProviderOptions: OpenAI config\", {\n      reasoningEffort,\n      thinkingLevel: effectiveThinking,\n      previousResponseId,\n      promptCacheKey,\n      truncation: truncationMode,\n    });\n\n    const options: ProviderOptions = {\n      openai: {\n        parallelToolCalls: true, // Always enable concurrent tool execution\n        serviceTier,\n        // Default to disabled; allow auto truncation for compaction to avoid context errors\n        truncation: truncationMode,\n        // Stable prompt cache key to improve OpenAI cache hit rates\n        // See: https://sdk.vercel.ai/providers/ai-sdk-providers/openai#responses-models\n        ...(promptCacheKey && { promptCacheKey }),\n        // Conditionally add reasoning configuration\n        ...(reasoningEffort && {\n          reasoningEffort,\n          reasoningSummary: \"detailed\", // Enable detailed reasoning summaries\n          // Include reasoning encrypted content to preserve reasoning context across conversation steps\n          // Required when using reasoning models (gpt-5, o3, o4-mini) with tool calls\n          // See: https://sdk.vercel.ai/providers/ai-sdk-providers/openai#responses-models\n          include: [\"reasoning.encrypted_content\"],\n        }),\n        // Include previousResponseId for conversation persistence\n        // OpenAI uses this to maintain reasoning state across turns\n        ...(previousResponseId && { previousResponseId }),\n      },\n    };\n    log.info(\"buildProviderOptions: Returning OpenAI options\", options);\n    return options;\n  }\n\n  // Build Google-specific options\n  if (provider === \"google\") {\n    const isGemini3 = modelString.includes(\"gemini-3\");\n    let thinkingConfig: GoogleGenerativeAIProviderOptions[\"thinkingConfig\"];\n\n    if (effectiveThinking !== \"off\") {\n      thinkingConfig = {\n        includeThoughts: true,\n      };\n\n      if (isGemini3) {\n        // Policy enforcement already clamped to valid levels for Flash/Pro,\n        // so effectiveThinking is guaranteed in the model's allowed set.\n        // Flash: off/low/medium/high; Pro: low/high. \"xhigh\" can't reach here.\n        thinkingConfig.thinkingLevel = effectiveThinking as Exclude<\n          ThinkingLevel,\n          \"off\" | \"xhigh\" | \"max\"\n        >;\n      } else {\n        // Gemini 2.5 uses thinkingBudget\n        const budget = GEMINI_THINKING_BUDGETS[effectiveThinking];\n        if (budget > 0) {\n          thinkingConfig.thinkingBudget = budget;\n        }\n      }\n    }\n\n    const options: ProviderOptions = {\n      google: {\n        thinkingConfig,\n      },\n    };\n    log.debug(\"buildProviderOptions: Google options\", options);\n    return options;\n  }\n\n  // Build OpenRouter-specific options\n  if (provider === \"openrouter\") {\n    const reasoningEffort = OPENROUTER_REASONING_EFFORT[effectiveThinking];\n\n    log.debug(\"buildProviderOptions: OpenRouter config\", {\n      reasoningEffort,\n      thinkingLevel: effectiveThinking,\n    });\n\n    // Only add reasoning config if thinking is enabled\n    if (reasoningEffort) {\n      const options: ProviderOptions = {\n        openrouter: {\n          reasoning: {\n            enabled: true,\n            effort: reasoningEffort,\n            // Don't exclude reasoning content - we want to display it in the UI\n            exclude: false,\n          },\n        },\n      };\n      log.debug(\"buildProviderOptions: Returning OpenRouter options\", options);\n      return options;\n    }\n\n    // No reasoning config needed when thinking is off\n    log.debug(\"buildProviderOptions: OpenRouter (thinking off, no provider options)\");\n    return {};\n  }\n\n  // Build xAI-specific options\n  if (provider === \"xai\") {\n    const overrides = muxProviderOptions?.xai ?? {};\n\n    const defaultSearchParameters: XaiProviderOptions[\"searchParameters\"] = {\n      mode: \"auto\",\n      returnCitations: true,\n    };\n\n    const options: ProviderOptions = {\n      xai: {\n        ...overrides,\n        searchParameters: overrides.searchParameters ?? defaultSearchParameters,\n      },\n    };\n    log.debug(\"buildProviderOptions: Returning xAI options\", options);\n    return options;\n  }\n\n  // No provider-specific options for unsupported providers\n  log.debug(\"buildProviderOptions: Unsupported provider\", provider);\n  return {};\n}\n"]}