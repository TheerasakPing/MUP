{"version":3,"file":"tokenMeterUtils.js","sourceRoot":"","sources":["../../../../src/common/utils/tokens/tokenMeterUtils.ts"],"names":[],"mappings":";;;;;;AACA,6CAA6C;AAC7C,yCAAiD;AAGjD,6EAA6E;AAC7E,sFAAsF;AACzE,QAAA,sBAAsB,GAAG;IACpC,MAAM,EAAE,0CAA0C;IAClD,WAAW,EAAE,mDAAmD;IAChE,KAAK,EAAE,4CAA4C;IACnD,MAAM,EAAE,8CAA8C;IACtD,QAAQ,EAAE,8CAA8C;CAChD,CAAC;AAuBX,MAAM,YAAY,GAAiB;IACjC,EAAE,IAAI,EAAE,QAAQ,EAAE,GAAG,EAAE,QAAQ,EAAE,KAAK,EAAE,QAAA,sBAAsB,CAAC,MAAM,EAAE,KAAK,EAAE,YAAY,EAAE;IAC5F;QACE,IAAI,EAAE,aAAa;QACnB,GAAG,EAAE,aAAa;QAClB,KAAK,EAAE,QAAA,sBAAsB,CAAC,WAAW;QACzC,KAAK,EAAE,cAAc;KACtB;IACD,EAAE,IAAI,EAAE,OAAO,EAAE,GAAG,EAAE,OAAO,EAAE,KAAK,EAAE,QAAA,sBAAsB,CAAC,KAAK,EAAE,KAAK,EAAE,OAAO,EAAE;IACpF,EAAE,IAAI,EAAE,QAAQ,EAAE,GAAG,EAAE,QAAQ,EAAE,KAAK,EAAE,QAAA,sBAAsB,CAAC,MAAM,EAAE,KAAK,EAAE,QAAQ,EAAE;IACxF;QACE,IAAI,EAAE,WAAW;QACjB,GAAG,EAAE,WAAW;QAChB,KAAK,EAAE,QAAA,sBAAsB,CAAC,QAAQ;QACtC,KAAK,EAAE,UAAU;KAClB;CACF,CAAC;AAEF;;;GAGG;AACH,iCACE,KAAmC,EACnC,KAAa,EACb,KAAc,EACd,mBAAmB,GAAG,KAAK,EAC3B,YAAkC,EAClB;IAChB,IAAI,CAAC,KAAK;QAAE,OAAO,EAAE,QAAQ,EAAE,EAAE,EAAE,WAAW,EAAE,CAAC,EAAE,eAAe,EAAE,CAAC,EAAE,CAAC;IAExE,MAAM,UAAU,GAAG,IAAA,0BAAa,EAAC,KAAK,EAAE,YAAY,CAAC,CAAC;IACtD,MAAM,SAAS,GAAG,KAAK,IAAI,IAAA,0BAAiB,EAAC,KAAK,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,UAAU,EAAE,gBAAgB,CAAC;IAE/F,oCAAoC;IACpC,qFAAqF;IACrF,mDAAmD;IACnD,MAAM,SAAS,GACb,KAAK,CAAC,KAAK,CAAC,MAAM;QAClB,KAAK,CAAC,MAAM,CAAC,MAAM;QACnB,KAAK,CAAC,WAAW,CAAC,MAAM;QACxB,KAAK,CAAC,MAAM,CAAC,MAAM;QACnB,KAAK,CAAC,SAAS,CAAC,MAAM,CAAC;IAEzB,MAAM,YAAY,GAAG,CAAC,MAAc,EAAE,EAAE,CAAC;QACvC,IAAI,mBAAmB,EAAE,CAAC;YACxB,OAAO,SAAS,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,GAAG,SAAS,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;QACxD,CAAC;QACD,OAAO,SAAS,CAAC,CAAC,CAAC,CAAC,MAAM,GAAG,SAAS,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,GAAG,SAAS,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;IAAA,CAChG,CAAC;IAEF,MAAM,QAAQ,GAAG,YAAY,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,EAAE,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,EAAE,CAAC,CAAC;QACrF,IAAI,EAAE,GAAG,CAAC,IAAI;QACd,MAAM,EAAE,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,MAAM;QAC7B,UAAU,EAAE,YAAY,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QAC/C,KAAK,EAAE,GAAG,CAAC,KAAK;KACjB,CAAC,CAAC,CAAC;IAEJ,MAAM,iBAAiB,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC,SAAS,GAAG,SAAS,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC;IAE1E,OAAO;QACL,QAAQ;QACR,WAAW,EAAE,SAAS;QACtB,SAAS;QACT,eAAe,EAAE,mBAAmB;YAClC,CAAC,CAAC,SAAS;gBACT,CAAC,CAAC,CAAC,SAAS,GAAG,SAAS,CAAC,GAAG,GAAG;gBAC/B,CAAC,CAAC,CAAC;YACL,CAAC,CAAC,iBAAiB;KACtB,CAAC;AAAA,CACH;AAED,sBAA6B,MAAc,EAAU;IACnD,IAAI,MAAM,IAAI,SAAS,EAAE,CAAC;QACxB,OAAO,GAAG,CAAC,MAAM,GAAG,SAAS,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC;IAC/C,CAAC;IACD,IAAI,MAAM,IAAI,KAAK,EAAE,CAAC;QACpB,OAAO,GAAG,CAAC,MAAM,GAAG,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC;IAC3C,CAAC;IACD,OAAO,MAAM,CAAC,cAAc,EAAE,CAAC;AAAA,CAChC;AAED,yBAAgC,IAA0B,EAAU;IAClE,OAAO,YAAY,CAAC,IAAI,CAAC,CAAC,GAAG,EAAE,EAAE,CAAC,GAAG,CAAC,IAAI,KAAK,IAAI,CAAC,EAAE,KAAK,IAAI,IAAI,CAAC;AAAA,CACrE","sourcesContent":["import type { ChatUsageDisplay } from \"./usageAggregator\";\nimport { getModelStats } from \"./modelStats\";\nimport { supports1MContext } from \"../ai/models\";\nimport type { CustomModelMetadata } from \"../../orpc/schemas/api\";\n\n// NOTE: Provide theme-matching fallbacks so token meters render consistently\n// even if a host environment doesn't define the CSS variables (e.g., an embedded UI).\nexport const TOKEN_COMPONENT_COLORS = {\n  cached: \"var(--color-token-cached, hsl(0 0% 50%))\",\n  cacheCreate: \"var(--color-token-cache-create, hsl(140 20% 55%))\",\n  input: \"var(--color-token-input, hsl(120 40% 35%))\",\n  output: \"var(--color-token-output, hsl(207 100% 40%))\",\n  thinking: \"var(--color-thinking-mode, hsl(271 76% 53%))\",\n} as const;\n\nexport interface TokenSegment {\n  type: \"cached\" | \"cacheCreate\" | \"input\" | \"output\" | \"reasoning\";\n  tokens: number;\n  percentage: number;\n  color: string;\n}\n\nexport interface TokenMeterData {\n  segments: TokenSegment[];\n  totalTokens: number;\n  maxTokens?: number;\n  totalPercentage: number;\n}\n\ninterface SegmentDef {\n  type: TokenSegment[\"type\"];\n  key: \"input\" | \"cached\" | \"cacheCreate\" | \"output\" | \"reasoning\";\n  color: string;\n  label: string;\n}\n\nconst SEGMENT_DEFS: SegmentDef[] = [\n  { type: \"cached\", key: \"cached\", color: TOKEN_COMPONENT_COLORS.cached, label: \"Cache Read\" },\n  {\n    type: \"cacheCreate\",\n    key: \"cacheCreate\",\n    color: TOKEN_COMPONENT_COLORS.cacheCreate,\n    label: \"Cache Create\",\n  },\n  { type: \"input\", key: \"input\", color: TOKEN_COMPONENT_COLORS.input, label: \"Input\" },\n  { type: \"output\", key: \"output\", color: TOKEN_COMPONENT_COLORS.output, label: \"Output\" },\n  {\n    type: \"reasoning\",\n    key: \"reasoning\",\n    color: TOKEN_COMPONENT_COLORS.thinking,\n    label: \"Thinking\",\n  },\n];\n\n/**\n * Calculate token meter data. When verticalProportions is true, segments are sized\n * proportionally to the request (e.g., 50% cached, 30% input) rather than context window.\n */\nexport function calculateTokenMeterData(\n  usage: ChatUsageDisplay | undefined,\n  model: string,\n  use1M: boolean,\n  verticalProportions = false,\n  customConfig?: CustomModelMetadata\n): TokenMeterData {\n  if (!usage) return { segments: [], totalTokens: 0, totalPercentage: 0 };\n\n  const modelStats = getModelStats(model, customConfig);\n  const maxTokens = use1M && supports1MContext(model) ? 1_000_000 : modelStats?.max_input_tokens;\n\n  // Total tokens used in the request.\n  // For Anthropic prompt caching, cacheCreate tokens are reported separately but still\n  // count toward total input tokens for the request.\n  const totalUsed =\n    usage.input.tokens +\n    usage.cached.tokens +\n    usage.cacheCreate.tokens +\n    usage.output.tokens +\n    usage.reasoning.tokens;\n\n  const toPercentage = (tokens: number) => {\n    if (verticalProportions) {\n      return totalUsed > 0 ? (tokens / totalUsed) * 100 : 0;\n    }\n    return maxTokens ? (tokens / maxTokens) * 100 : totalUsed > 0 ? (tokens / totalUsed) * 100 : 0;\n  };\n\n  const segments = SEGMENT_DEFS.filter((def) => usage[def.key].tokens > 0).map((def) => ({\n    type: def.type,\n    tokens: usage[def.key].tokens,\n    percentage: toPercentage(usage[def.key].tokens),\n    color: def.color,\n  }));\n\n  const contextPercentage = maxTokens ? (totalUsed / maxTokens) * 100 : 100;\n\n  return {\n    segments,\n    totalTokens: totalUsed,\n    maxTokens,\n    totalPercentage: verticalProportions\n      ? maxTokens\n        ? (totalUsed / maxTokens) * 100\n        : 0\n      : contextPercentage,\n  };\n}\n\nexport function formatTokens(tokens: number): string {\n  if (tokens >= 1_000_000) {\n    return `${(tokens / 1_000_000).toFixed(1)}M`;\n  }\n  if (tokens >= 1_000) {\n    return `${(tokens / 1_000).toFixed(1)}k`;\n  }\n  return tokens.toLocaleString();\n}\n\nexport function getSegmentLabel(type: TokenSegment[\"type\"]): string {\n  return SEGMENT_DEFS.find((def) => def.type === type)?.label ?? type;\n}\n"]}