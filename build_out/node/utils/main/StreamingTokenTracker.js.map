{"version":3,"file":"StreamingTokenTracker.js","sourceRoot":"","sources":["../../../../src/node/utils/main/StreamingTokenTracker.ts"],"names":[],"mappings":";AAAA;;;;;GAKG;;;AAEH,2CAAmE;AAEnE;;GAEG;AACH;IACU,SAAS,GAAqB,IAAI,CAAC;IAE3C;;;OAGG;IACH,KAAK,CAAC,QAAQ,CAAC,KAAa,EAAiB;QAC3C,IAAI,CAAC,SAAS,KAAd,IAAI,CAAC,SAAS,GAAK,MAAM,IAAA,gCAAoB,EAAC,KAAK,CAAC,EAAC;IAAA,CACtD;IAED;;;OAGG;IACH,KAAK,CAAC,WAAW,CAAC,IAAY,EAAmB;QAC/C,IAAI,CAAC,IAAI,CAAC,SAAS,IAAI,CAAC,IAAI;YAAE,OAAO,CAAC,CAAC;QACvC,OAAO,IAAI,CAAC,SAAS,CAAC,WAAW,CAAC,IAAI,CAAC,CAAC;IAAA,CACzC;CACF","sourcesContent":["/**\n * StreamingTokenTracker - Synchronous token counting for streaming deltas\n *\n * Simplified tracker that provides immediate token counts for each delta.\n * TPS calculation moved to frontend for better replay support and flexibility.\n */\n\nimport { getTokenizerForModel, type Tokenizer } from \"./tokenizer\";\n\n/**\n * StreamingTokenTracker provides synchronous token counting\n */\nexport class StreamingTokenTracker {\n  private tokenizer: Tokenizer | null = null;\n\n  /**\n   * Initialize tokenizer for the current model\n   * Should be called when model changes or on first stream\n   */\n  async setModel(model: string): Promise<void> {\n    this.tokenizer ??= await getTokenizerForModel(model);\n  }\n\n  /**\n   * Count tokens in a text string synchronously\n   * Performance: <1ms per delta with LRU caching\n   */\n  async countTokens(text: string): Promise<number> {\n    if (!this.tokenizer || !text) return 0;\n    return this.tokenizer.countTokens(text);\n  }\n}\n"]}