"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.ProviderModelFactory = exports.ANTHROPIC_1M_CONTEXT_HEADER = void 0;
exports.normalizeAnthropicBaseURL = normalizeAnthropicBaseURL;
exports.buildAnthropicHeaders = buildAnthropicHeaders;
exports.buildAppAttributionHeaders = buildAppAttributionHeaders;
exports.preloadAISDKProviders = preloadAISDKProviders;
exports.parseModelString = parseModelString;
exports.modelCostsIncluded = modelCostsIncluded;
const credential_providers_1 = require("@aws-sdk/credential-providers");
const result_1 = require("../../common/types/result");
const providers_1 = require("../../common/constants/providers");
const codexOAuth_1 = require("../../common/constants/codexOAuth");
const codexOauthAuth_1 = require("../../node/utils/codexOauthAuth");
const models_1 = require("../../common/utils/ai/models");
const appAttribution_1 = require("../../constants/appAttribution");
const providerRequirements_1 = require("../../node/utils/providerRequirements");
const gatewayStreamNormalization_1 = require("../../node/utils/gatewayStreamNormalization");
const undici_1 = require("undici");
// ---------------------------------------------------------------------------
// Undici agent with unlimited timeouts for AI streaming requests.
// Safe because users control cancellation via AbortSignal from the UI.
// Uses EnvHttpProxyAgent to automatically respect HTTP_PROXY, HTTPS_PROXY,
// and NO_PROXY environment variables for debugging/corporate network support.
// ---------------------------------------------------------------------------
const unlimitedTimeoutAgent = new undici_1.EnvHttpProxyAgent({
    bodyTimeout: 0, // No timeout - prevents BodyTimeoutError on long reasoning pauses
    headersTimeout: 0, // No timeout for headers
});
/**
 * Default fetch function with unlimited timeouts for AI streaming.
 * Uses undici Agent to remove artificial timeout limits while still
 * respecting user cancellation via AbortSignal.
 *
 * Note: If users provide custom fetch in providers.jsonc, they are
 * responsible for configuring timeouts appropriately. Custom fetch
 * implementations using undici should set bodyTimeout: 0 and
 * headersTimeout: 0 to prevent BodyTimeoutError on long-running
 * reasoning models.
 */
const defaultFetchWithUnlimitedTimeout = (async (input, init) => {
    // dispatcher is a Node.js undici-specific property for custom HTTP agents
    const requestInit = {
        ...(init ?? {}),
        dispatcher: unlimitedTimeoutAgent,
    };
    return fetch(input, requestInit);
});
const globalFetchWithExtras = fetch;
const defaultFetchWithExtras = defaultFetchWithUnlimitedTimeout;
if (typeof globalFetchWithExtras.preconnect === "function") {
    defaultFetchWithExtras.preconnect = globalFetchWithExtras.preconnect.bind(globalFetchWithExtras);
}
if (typeof globalFetchWithExtras.certificate === "function") {
    defaultFetchWithExtras.certificate =
        globalFetchWithExtras.certificate.bind(globalFetchWithExtras);
}
// ---------------------------------------------------------------------------
// Fetch wrappers
// ---------------------------------------------------------------------------
/**
 * Wrap fetch to inject Anthropic cache_control directly into the request body.
 * The AI SDK's providerOptions.anthropic.cacheControl doesn't get translated
 * to raw cache_control for tools or message content parts, so we inject it
 * at the HTTP level.
 *
 * Injects cache_control on:
 * 1. Last tool (caches all tool definitions)
 * 2. Last message's last content part (caches entire conversation)
 */
function wrapFetchWithAnthropicCacheControl(baseFetch) {
    const cachingFetch = async (input, init) => {
        // Only modify POST requests with JSON body
        if (init?.method?.toUpperCase() !== "POST" || typeof init?.body !== "string") {
            return baseFetch(input, init);
        }
        try {
            const json = JSON.parse(init.body);
            // Inject cache_control on the last tool if tools array exists
            if (Array.isArray(json.tools) && json.tools.length > 0) {
                const lastTool = json.tools[json.tools.length - 1];
                lastTool.cache_control ?? (lastTool.cache_control = { type: "ephemeral" });
            }
            // Inject cache_control on last message's last content part
            // This caches the entire conversation
            // Handle both formats:
            // - Direct Anthropic provider: json.messages (Anthropic API format)
            // - Gateway provider: json.prompt (AI SDK internal format)
            const messages = Array.isArray(json.messages)
                ? json.messages
                : Array.isArray(json.prompt)
                    ? json.prompt
                    : null;
            if (messages && messages.length >= 1) {
                const lastMsg = messages[messages.length - 1];
                // For gateway: add providerOptions.anthropic.cacheControl at message level
                // (gateway validates schema strictly, doesn't allow raw cache_control on messages)
                if (Array.isArray(json.prompt)) {
                    const providerOpts = (lastMsg.providerOptions ?? {});
                    const anthropicOpts = (providerOpts.anthropic ?? {});
                    anthropicOpts.cacheControl ?? (anthropicOpts.cacheControl = { type: "ephemeral" });
                    providerOpts.anthropic = anthropicOpts;
                    lastMsg.providerOptions = providerOpts;
                }
                // For direct Anthropic: add cache_control to last content part
                const content = lastMsg.content;
                if (Array.isArray(content) && content.length > 0) {
                    const lastPart = content[content.length - 1];
                    lastPart.cache_control ?? (lastPart.cache_control = { type: "ephemeral" });
                }
            }
            // Update body with modified JSON
            const newBody = JSON.stringify(json);
            const headers = new Headers(init?.headers);
            headers.delete("content-length"); // Body size changed
            return baseFetch(input, { ...init, headers, body: newBody });
        }
        catch {
            // If parsing fails, pass through unchanged
            return baseFetch(input, init);
        }
    };
    return Object.assign(cachingFetch, baseFetch);
}
/**
 * Wrap fetch so any mux-gateway 401 response clears local credentials (best-effort).
 *
 * This ensures the UI immediately reflects that the user has been logged out
 * when the gateway session expires.
 */
function wrapFetchWithMuxGatewayAutoLogout(baseFetch, providerService) {
    const wrappedFetch = async (input, init) => {
        const response = await baseFetch(input, init);
        if (response.status === 401) {
            try {
                providerService.setConfig("mux-gateway", ["couponCode"], "");
                providerService.setConfig("mux-gateway", ["voucher"], "");
            }
            catch {
                // Ignore failures clearing local credentials
            }
        }
        return response;
    };
    return Object.assign(wrappedFetch, baseFetch);
}
/**
 * Get fetch function for provider - use custom if provided, otherwise unlimited timeout default
 */
function getProviderFetch(providerConfig) {
    return typeof providerConfig.fetch === "function"
        ? providerConfig.fetch
        : defaultFetchWithUnlimitedTimeout;
}
// ---------------------------------------------------------------------------
// Exported helpers (re-exported from aiService.ts for backward compatibility)
// ---------------------------------------------------------------------------
/**
 * Normalize Anthropic base URL to ensure it ends with /v1 suffix.
 *
 * The Anthropic SDK expects baseURL to include /v1 (default: https://api.anthropic.com/v1).
 * Many users configure base URLs without the /v1 suffix, which causes API calls to fail.
 * This function automatically appends /v1 if missing.
 *
 * @param baseURL - The base URL to normalize (may or may not have /v1)
 * @returns The base URL with /v1 suffix
 */
function normalizeAnthropicBaseURL(baseURL) {
    const trimmed = baseURL.replace(/\/+$/, ""); // Remove trailing slashes
    if (trimmed.endsWith("/v1")) {
        return trimmed;
    }
    return `${trimmed}/v1`;
}
/** Header value for Anthropic 1M context beta */
exports.ANTHROPIC_1M_CONTEXT_HEADER = "context-1m-2025-08-07";
/**
 * Build headers for Anthropic provider, optionally including the 1M context beta header.
 * Exported for testing.
 */
function buildAnthropicHeaders(existingHeaders, use1MContext) {
    if (!use1MContext) {
        return existingHeaders;
    }
    if (existingHeaders) {
        return { ...existingHeaders, "anthropic-beta": exports.ANTHROPIC_1M_CONTEXT_HEADER };
    }
    return { "anthropic-beta": exports.ANTHROPIC_1M_CONTEXT_HEADER };
}
/**
 * Build app attribution headers used by OpenRouter (and other compatible platforms).
 *
 * Attribution docs:
 * - OpenRouter: https://openrouter.ai/docs/app-attribution
 * - Vercel AI Gateway: https://vercel.com/docs/ai-gateway/app-attribution
 *
 * Exported for testing.
 */
function buildAppAttributionHeaders(existingHeaders) {
    // Clone to avoid mutating caller-provided objects.
    const headers = existingHeaders ? { ...existingHeaders } : {};
    // Header names are case-insensitive. Preserve user-provided values by never overwriting.
    const existingLowercaseKeys = new Set(Object.keys(headers).map((key) => key.toLowerCase()));
    if (!existingLowercaseKeys.has("http-referer")) {
        headers["HTTP-Referer"] = appAttribution_1.MUX_APP_ATTRIBUTION_URL;
    }
    if (!existingLowercaseKeys.has("x-title")) {
        headers["X-Title"] = appAttribution_1.MUX_APP_ATTRIBUTION_TITLE;
    }
    return headers;
}
/**
 * Preload AI SDK provider modules to avoid race conditions in concurrent test environments.
 * This function loads @ai-sdk/anthropic, @ai-sdk/openai, and ollama-ai-provider-v2 eagerly
 * so that subsequent dynamic imports in createModel() hit the module cache instead of racing.
 *
 * In production, providers are lazy-loaded on first use to optimize startup time.
 * In tests, we preload them once during setup to ensure reliable concurrent execution.
 */
async function preloadAISDKProviders() {
    // Preload providers to ensure they're in the module cache before concurrent tests run
    await Promise.all(Object.values(providers_1.PROVIDER_REGISTRY).map((importFn) => importFn()));
}
/**
 * Parse provider and model ID from model string.
 * Handles model IDs with colons (e.g., "ollama:gpt-oss:20b").
 * Only splits on the first colon to support Ollama model naming convention.
 *
 * @param modelString - Model string in format "provider:model-id"
 * @returns Tuple of [providerName, modelId]
 * @example
 * parseModelString("anthropic:claude-opus-4") // ["anthropic", "claude-opus-4"]
 * parseModelString("ollama:gpt-oss:20b") // ["ollama", "gpt-oss:20b"]
 */
function parseModelString(modelString) {
    const colonIndex = modelString.indexOf(":");
    const providerName = colonIndex !== -1 ? modelString.slice(0, colonIndex) : modelString;
    const modelId = colonIndex !== -1 ? modelString.slice(colonIndex + 1) : "";
    return [providerName, modelId];
}
// ---------------------------------------------------------------------------
// Model cost tracking
// ---------------------------------------------------------------------------
const MUX_MODEL_COSTS_INCLUDED = Symbol("mux:modelCostsIncluded");
function markModelCostsIncluded(model) {
    model[MUX_MODEL_COSTS_INCLUDED] = true;
}
function modelCostsIncluded(model) {
    return model[MUX_MODEL_COSTS_INCLUDED] === true;
}
// ---------------------------------------------------------------------------
// Content extraction
// ---------------------------------------------------------------------------
/**
 * Extract text from AI SDK message content.
 * Content may be a plain string or a structured array like [{type:"text", text:"..."}].
 */
function extractTextContent(content) {
    if (typeof content === "string")
        return content.trim();
    if (Array.isArray(content)) {
        return content
            .filter((part) => typeof part === "object" &&
            part !== null &&
            part.type === "text" &&
            typeof part.text === "string")
            .map((part) => part.text)
            .join("")
            .trim();
    }
    return "";
}
// ---------------------------------------------------------------------------
// ProviderModelFactory
// ---------------------------------------------------------------------------
/**
 * Factory responsible for creating AI SDK LanguageModel instances from model strings.
 *
 * Extracted from AIService to isolate provider/model construction logic from the
 * streaming and orchestration concerns that AIService owns.
 */
class ProviderModelFactory {
    config;
    providerService;
    policyService;
    codexOauthService;
    constructor(config, providerService, policyService, codexOauthService) {
        this.config = config;
        this.providerService = providerService;
        this.policyService = policyService;
        this.codexOauthService = codexOauthService;
    }
    /**
     * Create an AI SDK model from a model string (e.g., "anthropic:claude-opus-4-1")
     *
     * IMPORTANT: We ONLY use providers.jsonc as the single source of truth for provider configuration.
     * We DO NOT use environment variables or default constructors that might read them.
     * This ensures consistent, predictable configuration management.
     *
     * Provider configuration from providers.jsonc is passed verbatim to the provider
     * constructor, ensuring automatic parity with Vercel AI SDK - any configuration options
     * supported by the provider will work without modification.
     */
    async createModel(modelString, muxProviderOptions) {
        try {
            // Parse model string (format: "provider:model-id")
            // Parse provider and model ID from model string
            const [providerName, modelId] = parseModelString(modelString);
            if (!providerName || !modelId) {
                return (0, result_1.Err)({
                    type: "invalid_model_string",
                    message: `Invalid model string format: "${modelString}". Expected "provider:model-id"`,
                });
            }
            // Check if provider is supported (prevents silent failures when adding to PROVIDER_REGISTRY
            // but forgetting to implement handler below)
            if (!(providerName in providers_1.PROVIDER_REGISTRY)) {
                return (0, result_1.Err)({
                    type: "provider_not_supported",
                    provider: providerName,
                });
            }
            if (this.policyService?.isEnforced()) {
                const provider = providerName;
                if (!this.policyService.isProviderAllowed(provider)) {
                    return (0, result_1.Err)({
                        type: "policy_denied",
                        message: `Provider ${providerName} is not allowed by policy`,
                    });
                }
                if (!this.policyService.isModelAllowed(provider, modelId)) {
                    return (0, result_1.Err)({
                        type: "policy_denied",
                        message: `Model ${providerName}:${modelId} is not allowed by policy`,
                    });
                }
            }
            // Load providers configuration - the ONLY source of truth
            const providersConfig = this.config.loadProvidersConfig();
            let providerConfig = providersConfig?.[providerName] ?? {};
            // Map baseUrl to baseURL if present (SDK expects baseURL)
            const { baseUrl, ...configWithoutBaseUrl } = providerConfig;
            providerConfig = baseUrl
                ? { ...configWithoutBaseUrl, baseURL: baseUrl }
                : configWithoutBaseUrl;
            // Policy: force provider base URL (if configured).
            const forcedBaseUrl = this.policyService?.isEnforced()
                ? this.policyService.getForcedBaseUrl(providerName)
                : undefined;
            if (forcedBaseUrl) {
                providerConfig = { ...providerConfig, baseURL: forcedBaseUrl };
            }
            // Inject app attribution headers (used by OpenRouter and other compatible platforms).
            // We never overwrite user-provided values (case-insensitive header matching).
            providerConfig = {
                ...providerConfig,
                headers: buildAppAttributionHeaders(providerConfig.headers),
            };
            // Handle Anthropic provider
            if (providerName === "anthropic") {
                // Resolve credentials from config + env (single source of truth)
                const creds = (0, providerRequirements_1.resolveProviderCredentials)("anthropic", providerConfig);
                if (!creds.isConfigured) {
                    return (0, result_1.Err)({ type: "api_key_not_found", provider: providerName });
                }
                // Build config with resolved credentials
                const configWithApiKey = creds.apiKey
                    ? { ...providerConfig, apiKey: creds.apiKey }
                    : providerConfig;
                // Normalize base URL to ensure /v1 suffix (SDK expects it)
                const effectiveBaseURL = configWithApiKey.baseURL ?? creds.baseUrl?.trim();
                const normalizedConfig = effectiveBaseURL
                    ? { ...configWithApiKey, baseURL: normalizeAnthropicBaseURL(effectiveBaseURL) }
                    : configWithApiKey;
                // Add 1M context beta header if requested and model supports it.
                // Check both per-model list (use1MContextModels) and legacy global flag (use1MContext).
                const fullModelId = `anthropic:${modelId}`;
                const is1MEnabled = ((muxProviderOptions?.anthropic?.use1MContextModels?.includes(fullModelId) ?? false) ||
                    muxProviderOptions?.anthropic?.use1MContext === true) &&
                    (0, models_1.supports1MContext)(fullModelId);
                const headers = buildAnthropicHeaders(normalizedConfig.headers, is1MEnabled);
                // Lazy-load Anthropic provider to reduce startup time
                const { createAnthropic } = await providers_1.PROVIDER_REGISTRY.anthropic();
                // Wrap fetch to inject cache_control on tools and messages
                // (SDK doesn't translate providerOptions to cache_control for these)
                // Use getProviderFetch to preserve any user-configured custom fetch (e.g., proxies)
                const baseFetch = getProviderFetch(providerConfig);
                const fetchWithCacheControl = wrapFetchWithAnthropicCacheControl(baseFetch);
                const provider = createAnthropic({
                    ...normalizedConfig,
                    headers,
                    fetch: fetchWithCacheControl,
                });
                return (0, result_1.Ok)(provider(modelId));
            }
            // Handle OpenAI provider (using Responses API)
            if (providerName === "openai") {
                const fullModelId = `${providerName}:${modelId}`;
                const codexOauthAllowed = (0, codexOAuth_1.isCodexOauthAllowedModelId)(fullModelId);
                const codexOauthRequired = (0, codexOAuth_1.isCodexOauthRequiredModelId)(fullModelId);
                const storedCodexOauth = (0, codexOauthAuth_1.parseCodexOauthAuth)(providerConfig.codexOauth);
                // Resolve credentials from config + env BEFORE OAuth checks so we can
                // fall back to an API key when OAuth is not connected.
                const creds = (0, providerRequirements_1.resolveProviderCredentials)("openai", providerConfig);
                // When a model requires Codex OAuth but the user hasn't connected it,
                // fall back to their API key instead of blocking entirely.  If the model
                // truly only works through OAuth, OpenAI's API will return a clear error.
                if (codexOauthRequired && !storedCodexOauth && !creds.isConfigured) {
                    return (0, result_1.Err)({ type: "oauth_not_connected", provider: providerName });
                }
                const codexOauthDefaultAuthRaw = providerConfig
                    .codexOauthDefaultAuth;
                const codexOauthDefaultAuth = codexOauthDefaultAuthRaw === "apiKey" ? "apiKey" : "oauth";
                // Codex OAuth routing:
                // - Required models route through ChatGPT OAuth when connected.
                // - If OAuth is not connected, fall back to API key (if available).
                // - Allowed models route through OAuth only when:
                //   - no API key is configured, OR
                //   - the user prefers OAuth when both are set.
                const shouldRouteThroughCodexOauth = (() => {
                    if (!codexOauthAllowed || !storedCodexOauth) {
                        return false;
                    }
                    if (codexOauthRequired) {
                        return true;
                    }
                    if (!creds.isConfigured) {
                        return true;
                    }
                    return codexOauthDefaultAuth === "oauth";
                })();
                if (!shouldRouteThroughCodexOauth && !creds.isConfigured) {
                    return (0, result_1.Err)({ type: "api_key_not_found", provider: providerName });
                }
                // Merge resolved credentials into config
                const configWithCreds = {
                    ...providerConfig,
                    // When using Codex OAuth, we overwrite auth headers in fetch(), so the OpenAI API key
                    // isn't required. Still pass a placeholder to ensure the SDK never reads env vars.
                    apiKey: shouldRouteThroughCodexOauth ? (creds.apiKey ?? "codex-oauth") : creds.apiKey,
                    ...(creds.baseUrl && !providerConfig.baseURL && { baseURL: creds.baseUrl }),
                    ...(creds.organization && { organization: creds.organization }),
                };
                // Extract serviceTier from config to pass through to buildProviderOptions
                const configServiceTier = providerConfig.serviceTier;
                if (configServiceTier && muxProviderOptions) {
                    muxProviderOptions.openai = {
                        ...muxProviderOptions.openai,
                        serviceTier: configServiceTier,
                    };
                }
                const baseFetch = getProviderFetch(providerConfig);
                const codexOauthService = this.codexOauthService;
                // Wrap fetch to default truncation to "disabled" for OpenAI Responses API calls.
                // This preserves our compaction handling while still allowing explicit truncation (e.g., auto).
                const fetchWithOpenAITruncation = Object.assign(async (input, init) => {
                    try {
                        const urlString = (() => {
                            if (typeof input === "string") {
                                return input;
                            }
                            if (input instanceof URL) {
                                return input.toString();
                            }
                            if (typeof input === "object" && input !== null && "url" in input) {
                                const possibleUrl = input.url;
                                if (typeof possibleUrl === "string") {
                                    return possibleUrl;
                                }
                            }
                            return "";
                        })();
                        const method = (init?.method ?? "GET").toUpperCase();
                        const isOpenAIResponses = /\/v1\/responses(\?|$)/.test(urlString);
                        const isOpenAIChatCompletions = /\/chat\/completions(\?|$)/.test(urlString);
                        let nextInput = input;
                        let nextInit = init;
                        const body = init?.body;
                        // Only parse the JSON body when routing through Codex OAuth — it needs
                        // instruction lifting, store=false, and truncation enforcement.  For
                        // non-Codex requests the SDK already sends the correct truncation value
                        // via providerOptions, so we skip the expensive parse + re-stringify.
                        if (shouldRouteThroughCodexOauth &&
                            isOpenAIResponses &&
                            method === "POST" &&
                            typeof body === "string") {
                            try {
                                const json = JSON.parse(body);
                                const truncation = json.truncation;
                                if (truncation !== "auto" && truncation !== "disabled") {
                                    json.truncation = "disabled";
                                }
                                // Codex OAuth (chatgpt.com/backend-api/codex/responses) rejects requests unless
                                // `instructions` is present and non-empty, and `store` is set to false.
                                // The AI SDK maps `system` prompts into the `input` array
                                // (role: system|developer) but does *not* automatically populate
                                // `instructions`, so we lift all system prompts into `instructions` when
                                // routing through Codex OAuth.
                                // Codex endpoint requires store=false and only accepts a subset of the
                                // standard OpenAI Responses API parameters. Use an allowlist to strip
                                // everything the endpoint doesn't understand (it rejects unknown params
                                // with 400).
                                json.store = false;
                                const CODEX_ALLOWED_PARAMS = new Set([
                                    "model",
                                    "input",
                                    "instructions",
                                    "tools",
                                    "tool_choice",
                                    "parallel_tool_calls",
                                    "stream",
                                    "store",
                                    "prompt_cache_key",
                                    "reasoning",
                                    "temperature",
                                    "top_p",
                                    "include",
                                    "text", // structured output via Output.object → text.format
                                ]);
                                for (const key of Object.keys(json)) {
                                    if (!CODEX_ALLOWED_PARAMS.has(key)) {
                                        delete json[key];
                                    }
                                }
                                // Filter out item_reference entries from the input. The AI SDK sends
                                // these as an optimization when store=true — bare { type: "item_reference",
                                // id: "rs_..." } objects that the server expands by looking up stored
                                // content. With store=false (required for Codex), these lookups fail.
                                // The full inline content is always present alongside references, so
                                // removing them doesn't lose conversation context.
                                if (Array.isArray(json.input)) {
                                    json.input = json.input.filter((item) => !(item && typeof item === "object" && item.type === "item_reference"));
                                }
                                const existingInstructions = typeof json.instructions === "string" ? json.instructions.trim() : "";
                                if (existingInstructions.length === 0) {
                                    const derivedParts = [];
                                    const keptInput = [];
                                    const responseInput = json.input;
                                    if (Array.isArray(responseInput)) {
                                        for (const item of responseInput) {
                                            if (!item || typeof item !== "object") {
                                                keptInput.push(item);
                                                continue;
                                            }
                                            const role = item.role;
                                            if (role !== "system" && role !== "developer") {
                                                keptInput.push(item);
                                                continue;
                                            }
                                            // Extract text from string content or structured content arrays
                                            // (AI SDK may produce [{type:"text", text:"..."}])
                                            const content = item.content;
                                            const text = extractTextContent(content);
                                            if (text.length > 0) {
                                                derivedParts.push(text);
                                            }
                                            // Drop this system/developer item from input (don't push to keptInput)
                                        }
                                        json.input = keptInput;
                                    }
                                    const joined = derivedParts.join("\n\n").trim();
                                    json.instructions = joined.length > 0 ? joined : "You are a helpful assistant.";
                                }
                                // Clone headers to avoid mutating caller-provided objects
                                const headers = new Headers(init?.headers);
                                // Remove content-length if present, since body will change
                                headers.delete("content-length");
                                const newBody = JSON.stringify(json);
                                nextInit = { ...init, headers, body: newBody };
                            }
                            catch {
                                // If body isn't JSON, fall through to normal fetch (but still allow Codex routing).
                            }
                        }
                        if (shouldRouteThroughCodexOauth && (isOpenAIResponses || isOpenAIChatCompletions)) {
                            if (!codexOauthService) {
                                throw new Error("Codex OAuth service not initialized");
                            }
                            const authResult = await codexOauthService.getValidAuth();
                            if (!authResult.success) {
                                throw new Error(authResult.error);
                            }
                            const headers = new Headers(nextInit?.headers);
                            headers.set("Authorization", `Bearer ${authResult.data.access}`);
                            if (authResult.data.accountId) {
                                headers.set("ChatGPT-Account-Id", authResult.data.accountId);
                            }
                            nextInput = codexOAuth_1.CODEX_ENDPOINT;
                            nextInit = { ...(nextInit ?? {}), headers };
                        }
                        return baseFetch(nextInput, nextInit);
                    }
                    catch (error) {
                        // For normal OpenAI (API key) requests, fall back to the original fetch on unexpected errors.
                        // For Codex OAuth routing, failures should surface (falling back would hit api.openai.com).
                        if (shouldRouteThroughCodexOauth) {
                            throw error;
                        }
                        return baseFetch(input, init);
                    }
                }, "preconnect" in baseFetch && typeof baseFetch.preconnect === "function"
                    ? {
                        preconnect: baseFetch.preconnect.bind(baseFetch),
                    }
                    : {});
                // Lazy-load OpenAI provider to reduce startup time
                const { createOpenAI } = await providers_1.PROVIDER_REGISTRY.openai();
                const provider = createOpenAI({
                    ...configWithCreds,
                    // Cast is safe: our fetch implementation is compatible with the SDK's fetch type.
                    // The preconnect method is optional in our implementation but required by the SDK type.
                    fetch: fetchWithOpenAITruncation,
                });
                // Use Responses API for persistence and built-in tools
                // OpenAI manages reasoning state via previousResponseId - no middleware needed
                const model = provider.responses(modelId);
                if (shouldRouteThroughCodexOauth) {
                    markModelCostsIncluded(model);
                    // Wrap model to inject store=false into providerOptions so the SDK
                    // sends full inline content instead of item_reference lookups.
                    // The Codex endpoint requires store=false; without this, the SDK
                    // defaults to store=true and sends bare { type: "item_reference" }
                    // items that can't be resolved.
                    const injectStoreFlag = (options) => {
                        const openaiOpts = options.providerOptions?.openai ?? {};
                        return {
                            ...options,
                            providerOptions: {
                                ...options.providerOptions,
                                openai: {
                                    ...openaiOpts,
                                    store: false,
                                },
                            },
                        };
                    };
                    const originalDoStream = model.doStream.bind(model);
                    const originalDoGenerate = model.doGenerate.bind(model);
                    model.doStream = (options) => originalDoStream(injectStoreFlag(options));
                    model.doGenerate = (options) => originalDoGenerate(injectStoreFlag(options));
                }
                return (0, result_1.Ok)(model);
            }
            // Handle xAI provider
            if (providerName === "xai") {
                // Resolve credentials from config + env (single source of truth)
                const creds = (0, providerRequirements_1.resolveProviderCredentials)("xai", providerConfig);
                if (!creds.isConfigured) {
                    return (0, result_1.Err)({ type: "api_key_not_found", provider: providerName });
                }
                const baseFetch = getProviderFetch(providerConfig);
                const { apiKey: _apiKey, baseURL, headers, ...extraOptions } = providerConfig;
                const { searchParameters, ...restOptions } = extraOptions;
                if (searchParameters && muxProviderOptions) {
                    const existingXaiOverrides = muxProviderOptions.xai ?? {};
                    muxProviderOptions.xai = {
                        ...existingXaiOverrides,
                        searchParameters: existingXaiOverrides.searchParameters ??
                            searchParameters,
                    };
                }
                const { createXai } = await providers_1.PROVIDER_REGISTRY.xai();
                const provider = createXai({
                    apiKey: creds.apiKey,
                    baseURL: creds.baseUrl ?? baseURL,
                    headers,
                    ...restOptions,
                    fetch: baseFetch,
                });
                return (0, result_1.Ok)(provider(modelId));
            }
            // Handle Ollama provider
            if (providerName === "ollama") {
                // Ollama doesn't require API key - it's a local service
                const baseFetch = getProviderFetch(providerConfig);
                // Lazy-load Ollama provider to reduce startup time
                const { createOllama } = await providers_1.PROVIDER_REGISTRY.ollama();
                const provider = createOllama({
                    ...providerConfig,
                    fetch: baseFetch,
                    // Use strict mode for better compatibility with Ollama API
                    compatibility: "strict",
                });
                return (0, result_1.Ok)(provider(modelId));
            }
            // Handle OpenRouter provider
            if (providerName === "openrouter") {
                // Resolve credentials from config + env (single source of truth)
                const creds = (0, providerRequirements_1.resolveProviderCredentials)("openrouter", providerConfig);
                if (!creds.isConfigured) {
                    return (0, result_1.Err)({ type: "api_key_not_found", provider: providerName });
                }
                const baseFetch = getProviderFetch(providerConfig);
                // Extract standard provider settings (apiKey, baseUrl, headers, fetch)
                const { apiKey: _apiKey, baseUrl, headers, fetch: _fetch, ...extraOptions } = providerConfig;
                // OpenRouter routing options that need to be nested under "provider" in API request
                // See: https://openrouter.ai/docs/features/provider-routing
                const OPENROUTER_ROUTING_OPTIONS = [
                    "order",
                    "allow_fallbacks",
                    "only",
                    "ignore",
                    "require_parameters",
                    "data_collection",
                    "sort",
                    "quantizations",
                ];
                // Build extraBody: routing options go under "provider", others stay at root
                const routingOptions = {};
                const otherOptions = {};
                for (const [key, value] of Object.entries(extraOptions)) {
                    if (OPENROUTER_ROUTING_OPTIONS.includes(key)) {
                        routingOptions[key] = value;
                    }
                    else {
                        otherOptions[key] = value;
                    }
                }
                // Build extraBody with provider nesting if routing options exist
                let extraBody;
                if (Object.keys(routingOptions).length > 0) {
                    extraBody = { provider: routingOptions, ...otherOptions };
                }
                else if (Object.keys(otherOptions).length > 0) {
                    extraBody = otherOptions;
                }
                // Lazy-load OpenRouter provider to reduce startup time
                const { createOpenRouter } = await providers_1.PROVIDER_REGISTRY.openrouter();
                const provider = createOpenRouter({
                    apiKey: creds.apiKey,
                    baseURL: creds.baseUrl ?? baseUrl,
                    headers,
                    fetch: baseFetch,
                    extraBody,
                });
                return (0, result_1.Ok)(provider(modelId));
            }
            // Handle Amazon Bedrock provider
            if (providerName === "bedrock") {
                // Resolve region from config + env (single source of truth)
                const creds = (0, providerRequirements_1.resolveProviderCredentials)("bedrock", providerConfig);
                if (!creds.isConfigured || !creds.region) {
                    return (0, result_1.Err)({ type: "api_key_not_found", provider: providerName });
                }
                const { region } = creds;
                // Optional AWS shared config profile name (equivalent to AWS_PROFILE).
                // Useful for SSO profiles when Mux isn't launched with AWS_PROFILE set.
                const profile = typeof providerConfig.profile === "string" && providerConfig.profile.trim()
                    ? providerConfig.profile.trim()
                    : undefined;
                const baseFetch = getProviderFetch(providerConfig);
                const { createAmazonBedrock } = await providers_1.PROVIDER_REGISTRY.bedrock();
                // Check if explicit credentials are provided in config
                const hasExplicitCredentials = providerConfig.accessKeyId && providerConfig.secretAccessKey;
                if (hasExplicitCredentials) {
                    // Use explicit credentials from providers.jsonc
                    const provider = createAmazonBedrock({
                        ...providerConfig,
                        region,
                        fetch: baseFetch,
                    });
                    return (0, result_1.Ok)(provider(modelId));
                }
                // Check for Bedrock bearer token (simplest auth) - from config or environment
                // The SDK's apiKey option maps to AWS_BEARER_TOKEN_BEDROCK
                const bearerToken = typeof providerConfig.bearerToken === "string" ? providerConfig.bearerToken : undefined;
                if (bearerToken) {
                    const provider = createAmazonBedrock({
                        region,
                        apiKey: bearerToken,
                        fetch: baseFetch,
                    });
                    return (0, result_1.Ok)(provider(modelId));
                }
                // Check if AWS_BEARER_TOKEN_BEDROCK env var is set
                if (process.env.AWS_BEARER_TOKEN_BEDROCK) {
                    // SDK automatically picks this up via apiKey option
                    const provider = createAmazonBedrock({
                        region,
                        fetch: baseFetch,
                    });
                    return (0, result_1.Ok)(provider(modelId));
                }
                // Use AWS credential provider chain for flexible authentication:
                // - Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
                // - Shared credentials file (~/.aws/credentials)
                // - EC2 instance profiles
                // - ECS task roles
                // - EKS service account (IRSA)
                // - SSO credentials
                // - And more...
                const provider = createAmazonBedrock({
                    region,
                    credentialProvider: (0, credential_providers_1.fromNodeProviderChain)(profile ? { profile } : {}),
                    fetch: baseFetch,
                });
                return (0, result_1.Ok)(provider(modelId));
            }
            // Handle Mux Gateway provider
            if (providerName === "mux-gateway") {
                // Resolve couponCode from config (single source of truth)
                const creds = (0, providerRequirements_1.resolveProviderCredentials)("mux-gateway", providerConfig);
                if (!creds.isConfigured || !creds.couponCode) {
                    return (0, result_1.Err)({ type: "api_key_not_found", provider: providerName });
                }
                const { couponCode } = creds;
                const { createGateway } = await providers_1.PROVIDER_REGISTRY["mux-gateway"]();
                // For Anthropic models via gateway, wrap fetch to inject cache_control on tools
                // (gateway provider doesn't process providerOptions.anthropic.cacheControl)
                // Use getProviderFetch to preserve any user-configured custom fetch (e.g., proxies)
                const baseFetch = getProviderFetch(providerConfig);
                const isAnthropicModel = modelId.startsWith("anthropic/");
                const fetchWithCacheControl = isAnthropicModel
                    ? wrapFetchWithAnthropicCacheControl(baseFetch)
                    : baseFetch;
                const fetchWithAutoLogout = wrapFetchWithMuxGatewayAutoLogout(fetchWithCacheControl, this.providerService);
                // Use configured baseURL or fall back to default gateway URL
                const gatewayBaseURL = providerConfig.baseURL ?? "https://gateway.mux.coder.com/api/v1/ai-gateway/v1/ai";
                const gateway = createGateway({
                    apiKey: couponCode,
                    baseURL: gatewayBaseURL,
                    fetch: fetchWithAutoLogout,
                });
                const model = gateway(modelId);
                // Normalize usage format from the gateway server.
                // The gateway SDK declares specificationVersion "v3", so the AI SDK core
                // expects nested v3 usage: { inputTokens: { total, ... }, outputTokens: { total, ... } }.
                // However the gateway server may return flat v2-style usage
                // (e.g. { inputTokens: 123, outputTokens: 456 }), causing
                // asLanguageModelUsage to produce undefined → 0 for all token counts.
                // These wrappers detect flat usage and convert to v3 nested format.
                const originalDoStream = model.doStream.bind(model);
                model.doStream = async (options) => {
                    const result = await originalDoStream(options);
                    return {
                        ...result,
                        // Type assertion safe: the transform only modifies the shape of usage/finishReason
                        // fields within existing chunks, it doesn't change the stream part types.
                        stream: result.stream.pipeThrough((0, gatewayStreamNormalization_1.normalizeGatewayStreamUsage)()),
                    };
                };
                const originalDoGenerate = model.doGenerate.bind(model);
                model.doGenerate = async (options) => {
                    const result = await originalDoGenerate(options);
                    return (0, gatewayStreamNormalization_1.normalizeGatewayGenerateResult)(result);
                };
                return (0, result_1.Ok)(model);
            }
            // GitHub Copilot — OpenAI-compatible with custom auth headers
            if (providerName === "github-copilot") {
                const creds = (0, providerRequirements_1.resolveProviderCredentials)("github-copilot", providerConfig);
                if (!creds.isConfigured) {
                    return (0, result_1.Err)({ type: "api_key_not_found", provider: providerName });
                }
                const { createOpenAICompatible } = await providers_1.PROVIDER_REGISTRY["github-copilot"]();
                const baseFetch = getProviderFetch(providerConfig);
                const copilotFetchFn = async (input, init) => {
                    const headers = new Headers(init?.headers);
                    headers.set("Authorization", `Bearer ${creds.apiKey ?? ""}`);
                    headers.set("Openai-Intent", "conversation-edits");
                    headers.delete("x-api-key");
                    return baseFetch(input, { ...init, headers });
                };
                const copilotFetch = Object.assign(copilotFetchFn, baseFetch);
                const baseURL = providerConfig.baseURL ?? "https://api.githubcopilot.com";
                const provider = createOpenAICompatible({
                    name: "github-copilot",
                    baseURL,
                    apiKey: "copilot", // placeholder — actual auth via custom fetch
                    fetch: copilotFetch,
                });
                return (0, result_1.Ok)(provider.chatModel(modelId));
            }
            // Generic handler for simple providers (standard API key + factory pattern)
            // Providers with custom logic (anthropic, openai, xai, ollama, openrouter, bedrock, mux-gateway,
            // github-copilot) are handled explicitly above. New providers using the standard pattern need
            // only be added to PROVIDER_DEFINITIONS - no code changes required here.
            const providerDef = providers_1.PROVIDER_DEFINITIONS[providerName];
            if (providerDef) {
                // Resolve credentials from config + env (single source of truth)
                const creds = (0, providerRequirements_1.resolveProviderCredentials)(providerName, providerConfig);
                if (providerDef.requiresApiKey && !creds.isConfigured) {
                    return (0, result_1.Err)({ type: "api_key_not_found", provider: providerName });
                }
                // Lazy-load and create provider using factoryName from definition
                const providerModule = (await providerDef.import());
                const factory = providerModule[providerDef.factoryName];
                if (!factory) {
                    return (0, result_1.Err)({
                        type: "provider_not_supported",
                        provider: providerName,
                    });
                }
                // Merge resolved credentials into config
                const configWithCreds = {
                    ...providerConfig,
                    ...(creds.apiKey && { apiKey: creds.apiKey }),
                    ...(creds.baseUrl && !providerConfig.baseURL && { baseURL: creds.baseUrl }),
                };
                const provider = factory({
                    ...configWithCreds,
                    fetch: getProviderFetch(providerConfig),
                });
                return (0, result_1.Ok)(provider(modelId));
            }
            return (0, result_1.Err)({
                type: "provider_not_supported",
                provider: providerName,
            });
        }
        catch (error) {
            const errorMessage = error instanceof Error ? error.message : String(error);
            return (0, result_1.Err)({ type: "unknown", raw: `Failed to create model: ${errorMessage}` });
        }
    }
    /**
     * Resolve model string (xAI variant mapping + gateway routing) and create the model.
     *
     * Combines the xAI thinking-level variant swap, gateway resolution, and model
     * creation into a single call. Previously this logic was inlined in
     * `AIService.streamMessage()`.
     *
     * @returns On success: the created model + resolution metadata.
     */
    async resolveAndCreateModel(modelString, thinkingLevel, muxProviderOptions) {
        const explicitlyRequestedGateway = modelString.trim().startsWith("mux-gateway:");
        const canonicalModelString = (0, models_1.normalizeGatewayModel)(modelString);
        let effectiveModelString = canonicalModelString;
        const [canonicalProviderName, canonicalModelId] = parseModelString(canonicalModelString);
        // xAI Grok: swap between reasoning and non-reasoning variants based on thinking level.
        // xAI only supports full reasoning (no medium/low).
        if (canonicalProviderName === "xai" && canonicalModelId === "grok-4-1-fast") {
            const variant = thinkingLevel !== "off" ? "grok-4-1-fast-reasoning" : "grok-4-1-fast-non-reasoning";
            effectiveModelString = `xai:${variant}`;
        }
        effectiveModelString = this.resolveGatewayModelString(effectiveModelString, canonicalModelString, explicitlyRequestedGateway);
        const routedThroughGateway = effectiveModelString.startsWith("mux-gateway:");
        const modelResult = await this.createModel(effectiveModelString, muxProviderOptions);
        if (!modelResult.success) {
            return (0, result_1.Err)(modelResult.error);
        }
        return (0, result_1.Ok)({
            model: modelResult.data,
            effectiveModelString,
            canonicalModelString,
            canonicalProviderName,
            canonicalModelId,
            routedThroughGateway,
        });
    }
    resolveGatewayModelString(modelString, modelKey, explicitlyRequestedGateway = false) {
        // Backend-authoritative routing avoids frontend localStorage races (issue #1769).
        const canonicalModelString = (0, models_1.normalizeGatewayModel)(modelString);
        const normalizedModelKey = modelKey ? (0, models_1.normalizeGatewayModel)(modelKey) : canonicalModelString;
        const [providerName, modelId] = parseModelString(canonicalModelString);
        if (!providerName || !modelId) {
            return canonicalModelString;
        }
        if (providerName === "mux-gateway" || !(providerName in providers_1.PROVIDER_REGISTRY)) {
            return canonicalModelString;
        }
        const typedProvider = providerName;
        if (!providers_1.MUX_GATEWAY_SUPPORTED_PROVIDERS.has(typedProvider)) {
            return canonicalModelString;
        }
        const config = this.config.loadConfigOrDefault();
        const gatewayEnabled = config.muxGatewayEnabled !== false;
        const gatewayModels = config.muxGatewayModels ?? [];
        // Legacy clients may still send mux-gateway model IDs before the backend config
        // has synchronized their allowlist, so honor an explicit mux-gateway prefix as
        // an implicit opt-in to avoid first-message API key failures.
        const isGatewayModelEnabled = explicitlyRequestedGateway ||
            gatewayModels.includes(canonicalModelString) ||
            gatewayModels.includes(normalizedModelKey);
        if (!gatewayEnabled || !isGatewayModelEnabled) {
            return canonicalModelString;
        }
        const providersConfig = this.config.loadProvidersConfig() ?? {};
        const gatewayConfig = providersConfig["mux-gateway"] ?? {};
        const gatewayConfigured = (0, providerRequirements_1.resolveProviderCredentials)("mux-gateway", gatewayConfig).isConfigured;
        if (!gatewayConfigured) {
            return canonicalModelString;
        }
        return `mux-gateway:${providerName}/${modelId}`;
    }
}
exports.ProviderModelFactory = ProviderModelFactory;
//# sourceMappingURL=providerModelFactory.js.map